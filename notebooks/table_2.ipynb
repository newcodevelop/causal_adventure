{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 1246182,
          "sourceType": "datasetVersion",
          "datasetId": 715500
        }
      ],
      "dockerImageVersionId": 30648,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/working/"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:00.731515Z",
          "iopub.execute_input": "2024-09-21T20:29:00.732336Z",
          "iopub.status.idle": "2024-09-21T20:29:01.725376Z",
          "shell.execute_reply.started": "2024-09-21T20:29:00.732290Z",
          "shell.execute_reply": "2024-09-21T20:29:01.724428Z"
        },
        "trusted": true,
        "id": "evKcUcvKZeXR",
        "outputId": "754c6c59-05ba-4067-f96b-abf11c81c517"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "25461.png\t   cr1.pt\t\t\t  mean_comparison_plot.png\n28076.png\t   cr2.pt\t\t\t  mr.pt\n94162.png\t   final_model_concept.pt\t  rr.npy\n96704.png\t   final_model_concept_inlp.pt\t  rr1.npy\ncausal_vb.pt\t   final_model_wo_adversarial.pt  transformers\ncausal_vb_inlp.pt  foo1.png\t\t\t  vs_tensors.pt\ncr.npy\t\t   full_annotation.pkl\t\t  y_p.pt\ncr.pt\t\t   image1.jpg\ncr1.npy\t\t   image2.jpg\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "\n",
        "import ipywidgets as widgets\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:06.076194Z",
          "iopub.execute_input": "2024-09-21T20:29:06.076917Z",
          "iopub.status.idle": "2024-09-21T20:29:06.160640Z",
          "shell.execute_reply.started": "2024-09-21T20:29:06.076880Z",
          "shell.execute_reply": "2024-09-21T20:29:06.159743Z"
        },
        "trusted": true,
        "id": "FCq0zOEFZeXU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SEED = 42\n",
        "FILE = '/kaggle/working/final_model_concept.pt'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:06.566545Z",
          "iopub.execute_input": "2024-09-21T20:29:06.567361Z",
          "iopub.status.idle": "2024-09-21T20:29:06.571080Z",
          "shell.execute_reply.started": "2024-09-21T20:29:06.567326Z",
          "shell.execute_reply": "2024-09-21T20:29:06.570229Z"
        },
        "trusted": true,
        "id": "nsCWXmM-ZeXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "ff = []"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:08.381438Z",
          "iopub.execute_input": "2024-09-21T20:29:08.381792Z",
          "iopub.status.idle": "2024-09-21T20:29:08.388061Z",
          "shell.execute_reply.started": "2024-09-21T20:29:08.381763Z",
          "shell.execute_reply": "2024-09-21T20:29:08.387206Z"
        },
        "trusted": true,
        "id": "2H2JNazEZeXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "!pip install jsonlines\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:08.814856Z",
          "iopub.execute_input": "2024-09-21T20:29:08.815713Z",
          "iopub.status.idle": "2024-09-21T20:29:22.037438Z",
          "shell.execute_reply.started": "2024-09-21T20:29:08.815677Z",
          "shell.execute_reply": "2024-09-21T20:29:22.036334Z"
        },
        "trusted": true,
        "id": "KbU_XIypZeXW",
        "outputId": "6b1587a3-2769-42e4-b597-98c591ed6e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting jsonlines\n  Downloading jsonlines-4.0.0-py3-none-any.whl.metadata (1.6 kB)\nRequirement already satisfied: attrs>=19.2.0 in /opt/conda/lib/python3.10/site-packages (from jsonlines) (23.2.0)\nDownloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: jsonlines\nSuccessfully installed jsonlines-4.0.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#RUN\n",
        "!pip install captum==0.7.0\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:22.039749Z",
          "iopub.execute_input": "2024-09-21T20:29:22.040043Z",
          "iopub.status.idle": "2024-09-21T20:29:34.784567Z",
          "shell.execute_reply.started": "2024-09-21T20:29:22.040016Z",
          "shell.execute_reply": "2024-09-21T20:29:34.783506Z"
        },
        "trusted": true,
        "id": "tqtBB-jDZeXW",
        "outputId": "81536fef-808b-48d1-8bcf-3cf8f287f2d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting captum==0.7.0\n  Downloading captum-0.7.0-py3-none-any.whl.metadata (26 kB)\nRequirement already satisfied: matplotlib in /opt/conda/lib/python3.10/site-packages (from captum==0.7.0) (3.7.4)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from captum==0.7.0) (1.24.4)\nRequirement already satisfied: torch>=1.6 in /opt/conda/lib/python3.10/site-packages (from captum==0.7.0) (2.1.2)\nRequirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from captum==0.7.0) (4.66.1)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.6->captum==0.7.0) (2023.12.2)\nRequirement already satisfied: contourpy>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (1.2.0)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (4.47.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (1.4.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (21.3)\nRequirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (9.5.0)\nRequirement already satisfied: pyparsing>=2.3.1 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (3.1.1)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.10/site-packages (from matplotlib->captum==0.7.0) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.7->matplotlib->captum==0.7.0) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6->captum==0.7.0) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6->captum==0.7.0) (1.3.0)\nDownloading captum-0.7.0-py3-none-any.whl (1.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: captum\nSuccessfully installed captum-0.7.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "import jsonlines"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:34.786088Z",
          "iopub.execute_input": "2024-09-21T20:29:34.786475Z",
          "iopub.status.idle": "2024-09-21T20:29:34.829066Z",
          "shell.execute_reply.started": "2024-09-21T20:29:34.786434Z",
          "shell.execute_reply": "2024-09-21T20:29:34.828299Z"
        },
        "trusted": true,
        "id": "BesqhvgqZeXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "!pip install wget\n",
        "#!pip install transformers"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:34.831073Z",
          "iopub.execute_input": "2024-09-21T20:29:34.831365Z",
          "iopub.status.idle": "2024-09-21T20:29:49.233811Z",
          "shell.execute_reply.started": "2024-09-21T20:29:34.831340Z",
          "shell.execute_reply": "2024-09-21T20:29:49.232895Z"
        },
        "trusted": true,
        "id": "MO5f27HsZeXX",
        "outputId": "1f7da65f-65ad-477a-b578-bb7d333ecd83"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting wget\n  Downloading wget-3.2.zip (10 kB)\n  Preparing metadata (setup.py) ... \u001b[?25ldone\n\u001b[?25hBuilding wheels for collected packages: wget\n  Building wheel for wget (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=1db1ceb5231a559a8ef8eccb0bca9cb3e2a75ee1f70417670fb7b61a1284b583\n  Stored in directory: /root/.cache/pip/wheels/8b/f1/7f/5c94f0a7a505ca1c81cd1d9208ae2064675d97582078e6c769\nSuccessfully built wget\nInstalling collected packages: wget\nSuccessfully installed wget-3.2\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "import sys\n",
        "sys.path.append('/kaggle/working/transformers/examples/research_projects/visual_bert')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:49.235189Z",
          "iopub.execute_input": "2024-09-21T20:29:49.235494Z",
          "iopub.status.idle": "2024-09-21T20:29:49.241912Z",
          "shell.execute_reply.started": "2024-09-21T20:29:49.235464Z",
          "shell.execute_reply": "2024-09-21T20:29:49.241228Z"
        },
        "trusted": true,
        "id": "pixh8r4JZeXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "import numpy as np\n",
        "import jsonlines\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sys\n",
        "import os\n",
        "from IPython.display import Image, display\n",
        "import PIL.Image\n",
        "import io\n",
        "import torch\n",
        "import numpy as np\n",
        "from processing_image import Preprocess\n",
        "from visualizing_image import SingleImageViz\n",
        "from modeling_frcnn import GeneralizedRCNN\n",
        "from utils import Config\n",
        "import utils\n",
        "from transformers import VisualBertForQuestionAnswering, BertTokenizerFast\n",
        "import pandas as pd\n",
        "import random\n",
        "from sklearn.model_selection import cross_val_score, cross_val_predict, KFold\n",
        "from sklearn import svm\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:49.242905Z",
          "iopub.execute_input": "2024-09-21T20:29:49.243139Z",
          "iopub.status.idle": "2024-09-21T20:29:59.113831Z",
          "shell.execute_reply.started": "2024-09-21T20:29:49.243118Z",
          "shell.execute_reply": "2024-09-21T20:29:59.112992Z"
        },
        "trusted": true,
        "id": "WPz-z6ssZeXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "train_file = '/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl'\n",
        "k =0\n",
        "with jsonlines.open(train_file) as reader:\n",
        "    for obj in reader:\n",
        "        print(obj['img'])\n",
        "        if k==9:\n",
        "            break\n",
        "        k+=1"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:59.114894Z",
          "iopub.execute_input": "2024-09-21T20:29:59.115332Z",
          "iopub.status.idle": "2024-09-21T20:29:59.127624Z",
          "shell.execute_reply.started": "2024-09-21T20:29:59.115307Z",
          "shell.execute_reply": "2024-09-21T20:29:59.126746Z"
        },
        "trusted": true,
        "id": "PL3XQCfbZeXY",
        "outputId": "21cfafe0-83b6-4f00-e1f0-e89555c46537"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "img/42953.png\nimg/23058.png\nimg/13894.png\nimg/37408.png\nimg/82403.png\nimg/16952.png\nimg/76932.png\nimg/70914.png\nimg/02973.png\nimg/58306.png\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "visual_feats = {}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:59.128636Z",
          "iopub.execute_input": "2024-09-21T20:29:59.128941Z",
          "iopub.status.idle": "2024-09-21T20:29:59.132995Z",
          "shell.execute_reply.started": "2024-09-21T20:29:59.128916Z",
          "shell.execute_reply": "2024-09-21T20:29:59.132153Z"
        },
        "trusted": true,
        "id": "o-ryAomtZeXY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "device = 'cuda'\n",
        "frcnn_cfg = Config.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\")\n",
        "frcnn_cfg.MODEL.device = device\n",
        "frcnn = GeneralizedRCNN.from_pretrained(\"unc-nlp/frcnn-vg-finetuned\", config=frcnn_cfg)\n",
        "image_preprocess = Preprocess(frcnn_cfg)\n",
        "frcnn.eval()\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:29:59.134197Z",
          "iopub.execute_input": "2024-09-21T20:29:59.134468Z",
          "iopub.status.idle": "2024-09-21T20:30:06.470279Z",
          "shell.execute_reply.started": "2024-09-21T20:29:59.134446Z",
          "shell.execute_reply": "2024-09-21T20:30:06.469249Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "ec84d414e95447dfa41584974e462db4",
            "33a0ae74120c4a7a94d3de4c0fd5f4c7"
          ]
        },
        "id": "3I7moGhnZeXZ",
        "outputId": "e14410d3-0a90-4c19-940e-833a4702860f"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "%s not found in cache or force_download set to True, downloading to %s https://s3.amazonaws.com/models.huggingface.co/bert/unc-nlp/frcnn-vg-finetuned/config.yaml /root/.cache/torch/transformers/tmpjdrzlwm3\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/2.13k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec84d414e95447dfa41584974e462db4"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "loading configuration file cache\n%s not found in cache or force_download set to True, downloading to %s https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin /root/.cache/torch/transformers/tmpdp33_yuo\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "Downloading:   0%|          | 0.00/262M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33a0ae74120c4a7a94d3de4c0fd5f4c7"
            }
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "loading weights file https://cdn.huggingface.co/unc-nlp/frcnn-vg-finetuned/pytorch_model.bin from cache at /root/.cache/torch/transformers/57f6df6abe353be2773f2700159c65615babf39ab5b48114d2b49267672ae10f.77b59256a4cf8343ae0f923246a81489fc8d82f98d082edc2d2037c977c0d9d0\nAll model checkpoint weights were used when initializing GeneralizedRCNN.\n\nAll the weights of GeneralizedRCNN were initialized from the model checkpoint at unc-nlp/frcnn-vg-finetuned.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use GeneralizedRCNN for predictions without further training.\n",
          "output_type": "stream"
        },
        {
          "execution_count": 13,
          "output_type": "execute_result",
          "data": {
            "text/plain": "GeneralizedRCNN(\n  (backbone): ResNet(\n    (stem): BasicStem(\n      (conv1): Conv2d(\n        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n        (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (res2): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv1): Conv2d(\n          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (res3): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv1): Conv2d(\n          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): BottleneckBlock(\n        (conv1): Conv2d(\n          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (res4): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv1): Conv2d(\n          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (3): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (4): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (5): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (6): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (7): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (8): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (9): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (10): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (11): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (12): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (13): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (14): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (15): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (16): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (17): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (18): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (19): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (20): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (21): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (22): BottleneckBlock(\n        (conv1): Conv2d(\n          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n          (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n  )\n  (proposal_generator): RPN(\n    (anchor_generator): AnchorGenerator(\n      (cell_anchors): ParameterList(  (0): Parameter containing: [torch.float32 of size 12x4 (cuda:0)])\n    )\n    (rpn_head): RPNHead(\n      (conv): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (objectness_logits): Conv2d(512, 12, kernel_size=(1, 1), stride=(1, 1))\n      (anchor_deltas): Conv2d(512, 48, kernel_size=(1, 1), stride=(1, 1))\n    )\n  )\n  (roi_heads): Res5ROIHeads(\n    (pooler): ROIPooler(\n      (level_poolers): ModuleList(\n        (0): RoIPool(output_size=(14, 14), spatial_scale=0.0625)\n      )\n    )\n    (res5): Sequential(\n      (0): BottleneckBlock(\n        (shortcut): Conv2d(\n          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv1): Conv2d(\n          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BottleneckBlock(\n        (conv1): Conv2d(\n          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (2): BottleneckBlock(\n        (conv1): Conv2d(\n          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv2): Conv2d(\n          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False\n          (norm): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n        (conv3): Conv2d(\n          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False\n          (norm): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n    )\n    (box_predictor): FastRCNNOutputLayers(\n      (cls_score): Linear(in_features=2048, out_features=1601, bias=True)\n      (bbox_pred): Linear(in_features=2048, out_features=6400, bias=True)\n      (cls_embedding): Embedding(1601, 256)\n      (fc_attr): Linear(in_features=2304, out_features=512, bias=True)\n      (attr_score): Linear(in_features=512, out_features=401, bias=True)\n    )\n  )\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "def get_visual_embedding(img_paths):\n",
        "    images, sizes, scales_yx = image_preprocess(img_paths) # img_paths -> list of image paths\n",
        "    output_dict = frcnn(\n",
        "      images,\n",
        "      sizes,\n",
        "      scales_yx=scales_yx,\n",
        "      padding=\"max_detections\",\n",
        "      max_detections=frcnn_cfg.max_detections,\n",
        "      return_tensors=\"pt\",\n",
        "    )\n",
        "    features = output_dict.get(\"roi_features\")\n",
        "    visual_embeds = features\n",
        "    visual_token_type_ids = torch.ones(visual_embeds.shape[:-1], dtype=torch.long)\n",
        "    visual_attention_mask = torch.ones(visual_embeds.shape[:-1], dtype=torch.float)\n",
        "    return visual_embeds,visual_token_type_ids,visual_attention_mask"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:06.475209Z",
          "iopub.execute_input": "2024-09-21T20:30:06.475519Z",
          "iopub.status.idle": "2024-09-21T20:30:06.481811Z",
          "shell.execute_reply.started": "2024-09-21T20:30:06.475494Z",
          "shell.execute_reply": "2024-09-21T20:30:06.480661Z"
        },
        "trusted": true,
        "id": "yXYHTUGJZeXZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "visual_feats = torch.load('./vs_tensors.pt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:06.483008Z",
          "iopub.execute_input": "2024-09-21T20:30:06.483355Z",
          "iopub.status.idle": "2024-09-21T20:30:09.492646Z",
          "shell.execute_reply.started": "2024-09-21T20:30:06.483312Z",
          "shell.execute_reply": "2024-09-21T20:30:09.491822Z"
        },
        "trusted": true,
        "id": "xRphtktuZeXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "len(visual_feats)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.493846Z",
          "iopub.execute_input": "2024-09-21T20:30:09.494211Z",
          "iopub.status.idle": "2024-09-21T20:30:09.499887Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.494161Z",
          "shell.execute_reply": "2024-09-21T20:30:09.499003Z"
        },
        "trusted": true,
        "id": "_O2MKlF_ZeXa",
        "outputId": "a103f90e-4d6d-4d4f-f1d1-e148da218df0"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 16,
          "output_type": "execute_result",
          "data": {
            "text/plain": "8500"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# visual_feats"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.500965Z",
          "iopub.execute_input": "2024-09-21T20:30:09.501258Z",
          "iopub.status.idle": "2024-09-21T20:30:09.530694Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.501234Z",
          "shell.execute_reply": "2024-09-21T20:30:09.529803Z"
        },
        "trusted": true,
        "id": "1tCYHMyQZeXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "import torch\n",
        "from torch.nn import functional as F\n",
        "import numpy as np\n",
        "from utils import Config\n",
        "import utils\n",
        "from transformers import VisualBertModel, BertTokenizer\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import accuracy_score,f1_score,roc_auc_score\n",
        "from scipy.special import softmax"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.531785Z",
          "iopub.execute_input": "2024-09-21T20:30:09.532065Z",
          "iopub.status.idle": "2024-09-21T20:30:09.541443Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.532041Z",
          "shell.execute_reply": "2024-09-21T20:30:09.540550Z"
        },
        "trusted": true,
        "id": "4OVDh8tzZeXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "train_set = []\n",
        "train_file = '/kaggle/input/facebook-hateful-meme-dataset/data/train.jsonl'\n",
        "k =0\n",
        "with jsonlines.open(train_file) as reader:\n",
        "    for obj in reader:\n",
        "    #         print(obj['img'])\n",
        "\n",
        "        train_set.append({'text': obj['text'],\n",
        "\n",
        "                       'img': obj['img'],\n",
        "\n",
        "                       'label': int(obj['label'])})\n",
        "    #         print(k)\n",
        "    #         if k==1500:\n",
        "    #             break\n",
        "        k+=1\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.542501Z",
          "iopub.execute_input": "2024-09-21T20:30:09.542816Z",
          "iopub.status.idle": "2024-09-21T20:30:09.586592Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.542784Z",
          "shell.execute_reply": "2024-09-21T20:30:09.585821Z"
        },
        "trusted": true,
        "id": "kIGk9FUvZeXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "len(train_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.587532Z",
          "iopub.execute_input": "2024-09-21T20:30:09.587793Z",
          "iopub.status.idle": "2024-09-21T20:30:09.593365Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.587771Z",
          "shell.execute_reply": "2024-09-21T20:30:09.592468Z"
        },
        "trusted": true,
        "id": "rFayNoHFZeXb",
        "outputId": "07ddb783-4810-4005-9800-6c341658529e"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 20,
          "output_type": "execute_result",
          "data": {
            "text/plain": "8500"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "class CustomDataset(Dataset):\n",
        "\n",
        "    def __init__(self, ds, max_len=64):\n",
        "        self.ds = ds\n",
        "        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "        self.model = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
        "\n",
        "\n",
        "        self.max_len = max_len\n",
        "    def __len__(self):\n",
        "        return len(self.ds)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        ds_idx = self.ds[index]\n",
        "        inputs = self.tokenizer(ds_idx['text'], padding=\"max_length\", truncation=True, max_length=self.max_len, return_tensors='pt')\n",
        "\n",
        "\n",
        "        inputs['input_ids'] = inputs['input_ids'].squeeze(0)\n",
        "        inputs['token_type_ids'] = inputs['token_type_ids'].squeeze(0)\n",
        "        inputs['attention_mask'] = inputs['attention_mask'].squeeze(0)\n",
        "\n",
        "        # visual_embeds,visual_token_type_ids,visual_attention_mask = get_visual_embedding('./data/'+ds_idx['img'])\n",
        "        visual_embeds,visual_token_type_ids,visual_attention_mask = visual_feats[ds_idx['img']]\n",
        "\n",
        "        #print(ds_idx['img'])\n",
        "\n",
        "        inputs.update({\n",
        "          \"visual_embeds\": torch.squeeze(visual_embeds),\n",
        "          \"visual_token_type_ids\": torch.squeeze(visual_token_type_ids),\n",
        "          \"visual_attention_mask\": torch.squeeze(visual_attention_mask)\n",
        "        })\n",
        "\n",
        "\n",
        "\n",
        "        #inputs.update({\"path\": ds_idx['img']})\n",
        "\n",
        "        return inputs, int(ds_idx['label'])\n",
        "\n",
        "t = CustomDataset(train_set)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:09.594492Z",
          "iopub.execute_input": "2024-09-21T20:30:09.594768Z",
          "iopub.status.idle": "2024-09-21T20:30:16.154942Z",
          "shell.execute_reply.started": "2024-09-21T20:30:09.594735Z",
          "shell.execute_reply": "2024-09-21T20:30:16.154078Z"
        },
        "trusted": true,
        "colab": {
          "referenced_widgets": [
            "8f86e71d7716415dbc5f1c971a6eb12b",
            "fb769f1d3ba2430b864ba80cc5a61bb3",
            "45315dcafd8149e0919753ff9c6a8fc6",
            "b9d20ea9a71c4bf1aba1c1c0f710fef4",
            "884bbc2c580e49049ad54c47a993ebec",
            "7d3dabfd5fc6433cbe4dc4c93c072487"
          ]
        },
        "id": "VWrjcw52ZeXb",
        "outputId": "90c0c27c-80f4-4b97-8ae5-5615f4090dde"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f86e71d7716415dbc5f1c971a6eb12b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb769f1d3ba2430b864ba80cc5a61bb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "45315dcafd8149e0919753ff9c6a8fc6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b9d20ea9a71c4bf1aba1c1c0f710fef4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "config.json:   0%|          | 0.00/631 [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "884bbc2c580e49049ad54c47a993ebec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "pytorch_model.bin:   0%|          | 0.00/448M [00:00<?, ?B/s]",
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d3dabfd5fc6433cbe4dc4c93c072487"
            }
          },
          "metadata": {}
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!export CUBLAS_WORKSPACE_CONFIG=:16:8"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.156318Z",
          "iopub.execute_input": "2024-09-21T20:30:16.156837Z",
          "iopub.status.idle": "2024-09-21T20:30:16.161021Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.156809Z",
          "shell.execute_reply": "2024-09-21T20:30:16.159993Z"
        },
        "trusted": true,
        "id": "U-JKJUeiZeXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "seed=SEED\n",
        "random.seed(seed)     # python random generator\n",
        "np.random.seed(seed)  # numpy random generator\n",
        "\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "#torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.162168Z",
          "iopub.execute_input": "2024-09-21T20:30:16.162478Z",
          "iopub.status.idle": "2024-09-21T20:30:16.279978Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.162453Z",
          "shell.execute_reply": "2024-09-21T20:30:16.279014Z"
        },
        "trusted": true,
        "id": "GykCEr5fZeXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(t)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.281033Z",
          "iopub.execute_input": "2024-09-21T20:30:16.281318Z",
          "iopub.status.idle": "2024-09-21T20:30:16.292127Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.281294Z",
          "shell.execute_reply": "2024-09-21T20:30:16.291235Z"
        },
        "trusted": true,
        "id": "Kriul_KGZeXc",
        "outputId": "8a13b105-a9d0-414e-ff61-893a627fdbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 24,
          "output_type": "execute_result",
          "data": {
            "text/plain": "8500"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "torch.manual_seed(42)\n",
        "t_p,te_p = torch.utils.data.random_split(t,[7840,660])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.293245Z",
          "iopub.execute_input": "2024-09-21T20:30:16.293506Z",
          "iopub.status.idle": "2024-09-21T20:30:16.304466Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.293484Z",
          "shell.execute_reply": "2024-09-21T20:30:16.303711Z"
        },
        "trusted": true,
        "id": "5Z3pow9DZeXc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(t_p, shuffle=True, batch_size=32)\n",
        "eval_dataloader = DataLoader(te_p, batch_size=1)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.305433Z",
          "iopub.execute_input": "2024-09-21T20:30:16.305715Z",
          "iopub.status.idle": "2024-09-21T20:30:16.311578Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.305692Z",
          "shell.execute_reply": "2024-09-21T20:30:16.310555Z"
        },
        "trusted": true,
        "id": "__KALefwZeXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.312612Z",
          "iopub.execute_input": "2024-09-21T20:30:16.312876Z",
          "iopub.status.idle": "2024-09-21T20:30:16.321504Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.312853Z",
          "shell.execute_reply": "2024-09-21T20:30:16.320624Z"
        },
        "trusted": true,
        "id": "cglbNkUTZeXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('h')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.322616Z",
          "iopub.execute_input": "2024-09-21T20:30:16.322938Z",
          "iopub.status.idle": "2024-09-21T20:30:16.332734Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.322907Z",
          "shell.execute_reply": "2024-09-21T20:30:16.331675Z"
        },
        "trusted": true,
        "id": "zZxh-1OQZeXd",
        "outputId": "cf2ab782-33f7-4e72-810a-d26998fdc55a"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "h\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "concept_classes = [\"holocaust\", \"nazism\", \"genocide\", \"funny\", \"anti muslim\", \"terrorism\", \"violence\", \"politics\", \"racism\", \"international relation\", \"adult\", \"gore\", \"misogynistic\", \"immigration\", \"extremism\", \"immoral\", \"white supremacy\", \"indecency\"]\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.333926Z",
          "iopub.execute_input": "2024-09-21T20:30:16.334268Z",
          "iopub.status.idle": "2024-09-21T20:30:16.341582Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.334234Z",
          "shell.execute_reply": "2024-09-21T20:30:16.340787Z"
        },
        "trusted": true,
        "id": "pnrDgr0xZeXd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(concept_classes)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:16.342554Z",
          "iopub.execute_input": "2024-09-21T20:30:16.342847Z",
          "iopub.status.idle": "2024-09-21T20:30:16.356940Z",
          "shell.execute_reply.started": "2024-09-21T20:30:16.342824Z",
          "shell.execute_reply": "2024-09-21T20:30:16.356149Z"
        },
        "trusted": true,
        "id": "Gq13pTPZZeXe",
        "outputId": "dc8fda43-a45c-4ef3-dfee-63bb5b698f8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 30,
          "output_type": "execute_result",
          "data": {
            "text/plain": "18"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#cnt"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:24.622593Z",
          "iopub.execute_input": "2024-09-21T20:30:24.623360Z",
          "iopub.status.idle": "2024-09-21T20:30:24.627249Z",
          "shell.execute_reply.started": "2024-09-21T20:30:24.623321Z",
          "shell.execute_reply": "2024-09-21T20:30:24.626232Z"
        },
        "trusted": true,
        "id": "fiU2bD7gZeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XPPFMnJ_ZeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "czbGxMCLZeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V8VhRh4GZeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W7_51TiLZeXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "e8CN46HWZeXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "hZYkSSELZeXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "with open('/kaggle/working/full_annotation.pkl', 'rb') as f:\n",
        "    mynewlist = pickle.load(f)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:26.878358Z",
          "iopub.execute_input": "2024-09-21T20:30:26.878699Z",
          "iopub.status.idle": "2024-09-21T20:30:26.883706Z",
          "shell.execute_reply.started": "2024-09-21T20:30:26.878675Z",
          "shell.execute_reply": "2024-09-21T20:30:26.882640Z"
        },
        "trusted": true,
        "id": "gejI2Nq-ZeXf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(mynewlist)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:27.502694Z",
          "iopub.execute_input": "2024-09-21T20:30:27.503087Z",
          "iopub.status.idle": "2024-09-21T20:30:27.509046Z",
          "shell.execute_reply.started": "2024-09-21T20:30:27.503057Z",
          "shell.execute_reply": "2024-09-21T20:30:27.508150Z"
        },
        "trusted": true,
        "id": "WDYHj4QDZeXf",
        "outputId": "23d57961-badd-4b43-fbec-9c8eda5a8262"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 33,
          "output_type": "execute_result",
          "data": {
            "text/plain": "208"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "W7956smIZeXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "gc=mynewlist"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:29.351283Z",
          "iopub.execute_input": "2024-09-21T20:30:29.351659Z",
          "iopub.status.idle": "2024-09-21T20:30:29.355720Z",
          "shell.execute_reply.started": "2024-09-21T20:30:29.351629Z",
          "shell.execute_reply": "2024-09-21T20:30:29.354814Z"
        },
        "trusted": true,
        "id": "yb87TKxhZeXk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "device='cuda'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:29.678855Z",
          "iopub.execute_input": "2024-09-21T20:30:29.679524Z",
          "iopub.status.idle": "2024-09-21T20:30:29.683302Z",
          "shell.execute_reply.started": "2024-09-21T20:30:29.679492Z",
          "shell.execute_reply": "2024-09-21T20:30:29.682319Z"
        },
        "trusted": true,
        "id": "BLCqgb4aZeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b1q9UjlHZeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:30.385816Z",
          "iopub.execute_input": "2024-09-21T20:30:30.386432Z",
          "iopub.status.idle": "2024-09-21T20:30:30.391992Z",
          "shell.execute_reply.started": "2024-09-21T20:30:30.386399Z",
          "shell.execute_reply": "2024-09-21T20:30:30.391089Z"
        },
        "trusted": true,
        "id": "kzxAnkUCZeXl",
        "outputId": "24450e4f-c23e-4c36-8bd9-2534e46468c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 36,
          "output_type": "execute_result",
          "data": {
            "text/plain": "'cuda'"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:32.811130Z",
          "iopub.execute_input": "2024-09-21T20:30:32.812068Z",
          "iopub.status.idle": "2024-09-21T20:30:32.951955Z",
          "shell.execute_reply.started": "2024-09-21T20:30:32.812034Z",
          "shell.execute_reply": "2024-09-21T20:30:32.951183Z"
        },
        "trusted": true,
        "id": "8kbA3-olZeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.encode(\"jew\")[1:-1]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:33.519302Z",
          "iopub.execute_input": "2024-09-21T20:30:33.519973Z",
          "iopub.status.idle": "2024-09-21T20:30:33.526328Z",
          "shell.execute_reply.started": "2024-09-21T20:30:33.519940Z",
          "shell.execute_reply": "2024-09-21T20:30:33.525506Z"
        },
        "trusted": true,
        "id": "VoInVbWXZeXl",
        "outputId": "a9e5553d-4169-41cf-a496-8a96c7d11eb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 38,
          "output_type": "execute_result",
          "data": {
            "text/plain": "[16522]"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "DYN_ROUTE = True\n",
        "DECONFOUND = True"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:34.870977Z",
          "iopub.execute_input": "2024-09-21T20:30:34.871715Z",
          "iopub.status.idle": "2024-09-21T20:30:34.875782Z",
          "shell.execute_reply.started": "2024-09-21T20:30:34.871683Z",
          "shell.execute_reply": "2024-09-21T20:30:34.874736Z"
        },
        "trusted": true,
        "id": "4neoko-wZeXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "!pip install pytorch_revgrad\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:35.633687Z",
          "iopub.execute_input": "2024-09-21T20:30:35.634363Z",
          "iopub.status.idle": "2024-09-21T20:30:49.500805Z",
          "shell.execute_reply.started": "2024-09-21T20:30:35.634330Z",
          "shell.execute_reply": "2024-09-21T20:30:49.499742Z"
        },
        "trusted": true,
        "id": "-tFKJdozZeXm",
        "outputId": "7a0e458e-f21f-4206-b0fa-337d4d8b5eab"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting pytorch_revgrad\n  Downloading pytorch_revgrad-0.2.0-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from pytorch_revgrad) (1.24.4)\nRequirement already satisfied: torch>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from pytorch_revgrad) (2.1.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (3.13.1)\nRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (4.9.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (3.1.2)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch>=1.0.0->pytorch_revgrad) (2023.12.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.0.0->pytorch_revgrad) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.0.0->pytorch_revgrad) (1.3.0)\nDownloading pytorch_revgrad-0.2.0-py3-none-any.whl (4.6 kB)\nInstalling collected packages: pytorch_revgrad\nSuccessfully installed pytorch_revgrad-0.2.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.nn.Parameter(torch.tensor(0.1))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:49.502792Z",
          "iopub.execute_input": "2024-09-21T20:30:49.503106Z",
          "iopub.status.idle": "2024-09-21T20:30:49.507644Z",
          "shell.execute_reply.started": "2024-09-21T20:30:49.503077Z",
          "shell.execute_reply": "2024-09-21T20:30:49.506636Z"
        },
        "trusted": true,
        "id": "bJBJfCygZeXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "num_concepts = 18\n",
        "#BS = 8\n",
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_revgrad import RevGrad\n",
        "class VB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VB, self).__init__()\n",
        "        self.vb = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.linear_relu_stack_latent = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.linear_relu_stack_hidden = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "        #self.w = torch.nn.Parameter(torch.ones(11,1)/11)\n",
        "        self.w = torch.nn.Parameter(torch.ones(num_concepts,1))\n",
        "\n",
        "        self.project_latent = nn.Linear(768,2048)\n",
        "\n",
        "        #self.W_ij = [[nn.Linear(768,768) for i in range(64)] for j in range(17)]\n",
        "\n",
        "        self.W_ij = torch.nn.Parameter(torch.randn(18,64,28,28))\n",
        "\n",
        "        self.proj_conc = nn.Linear(768,28)\n",
        "        self.proj_embed = nn.Linear(768,28)\n",
        "\n",
        "\n",
        "\n",
        "        self.grad_rev1 = RevGrad()\n",
        "        self.grad_rev2 = RevGrad()\n",
        "\n",
        "        self.w1 = torch.nn.Parameter(torch.tensor(0.2))\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "        all_concepts_,\n",
        "        input_ids = None,\n",
        "        attention_mask = None,\n",
        "        token_type_ids = None,\n",
        "        position_ids = None,\n",
        "        head_mask = None,\n",
        "        inputs_embeds = None,\n",
        "        visual_embeds = None,\n",
        "        visual_attention_mask = None,\n",
        "        visual_token_type_ids = None,\n",
        "        image_text_alignment = None,\n",
        "        output_attentions = None,\n",
        "        output_hidden_states = None,\n",
        "        return_dict = None):\n",
        "\n",
        "        #         print(all_concepts.shape)\n",
        "\n",
        "        B = visual_embeds.size(0)\n",
        "\n",
        "        #         print(B)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ##############################################\n",
        "\n",
        "        all_concepts = self.proj_conc(all_concepts_)\n",
        "\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = self.vb.embeddings.word_embeddings(input_ids)\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        inputs_embeds = self.proj_embed(inputs_embeds)\n",
        "\n",
        "\n",
        "        #####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #b1 = torch.bmm(inputs_embeds,all_concepts.repeat(B,1,1).transpose(1,2))\n",
        "\n",
        "        #print(inputs_embeds.shape)\n",
        "        #print(all_concepts.repeat(B,1,1).transpose(1,2).shape)\n",
        "\n",
        "        #b,64,28\n",
        "        #b,28,17\n",
        "\n",
        "\n",
        "        b = torch.einsum('blx,bxn->bln',inputs_embeds,all_concepts.repeat(B,1,1).transpose(1,2))\n",
        "\n",
        "        #         print(b1)\n",
        "\n",
        "        #         print('********')\n",
        "\n",
        "        #         print(b2)\n",
        "\n",
        "        #         print(torch.equal(b1,b2))\n",
        "\n",
        "\n",
        "\n",
        "        b = b.masked_fill(~attention_mask.unsqueeze(dim=2).bool(), -np.inf)\n",
        "        c = F.softmax(b,dim=1)\n",
        "\n",
        "\n",
        "\n",
        "        #inter = torch.einsum('bcsn,csnn->bcsn',inputs_embeds.unsqueeze(1).repeat(1,17,1,1), self.W_ij)\n",
        "\n",
        "        #print(inter[:,0,0,:])\n",
        "\n",
        "        einsum_expression = 'bln,clnx->bclx'\n",
        "        inter = torch.einsum(einsum_expression, inputs_embeds, self.W_ij)\n",
        "\n",
        "        k = torch.einsum('bcsn,bsc->bcn',inter,c)\n",
        "        norm = torch.norm(k,dim=2)\n",
        "\n",
        "\n",
        "\n",
        "        kk1 = ((norm**2)/(1+norm**2)).unsqueeze(dim=2) * (k/norm.unsqueeze(dim=2))\n",
        "\n",
        "        w_dynamic = kk1.norm(dim=2).unsqueeze(2)\n",
        "\n",
        "\n",
        "        raw_latent = (1-self.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * self.w.unsqueeze(dim=0).repeat(B,1,1) + all_concepts_.unsqueeze(0).repeat(B,1,1) * w_dynamic * self.w1\n",
        "\n",
        "        raw_latent = torch.mean(raw_latent, dim=1)\n",
        "\n",
        "        #raw_latent = torch.mean(all_concepts*self.w,dim=0)\n",
        "        #raw_latent = raw_latent.unsqueeze(dim=0)\n",
        "\n",
        "        latent = self.project_latent(raw_latent)\n",
        "\n",
        "\n",
        "\n",
        "        latent = latent.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        visual_embeds_latent = torch.cat((visual_embeds,latent),dim=1)\n",
        "\n",
        "\n",
        "        ################################################################\n",
        "\n",
        "\n",
        "        #print(b)\n",
        "\n",
        "        #######################################################\n",
        "        #         print(b.shape)\n",
        "\n",
        "        #         b = []\n",
        "        #         for i in range(64):\n",
        "        #             bi = []\n",
        "        #             for j in range(17):\n",
        "        #                 #print(inputs_embeds[:,i,:].shape)\n",
        "        #                 ci = all_concepts[j].unsqueeze(0).repeat(32,1,1).squeeze()\n",
        "        #                 uj = inputs_embeds[:,i,:]\n",
        "        #                 #print(ci.shape)\n",
        "        #                 bij = torch.bmm(uj.unsqueeze(dim=1), ci.unsqueeze(dim=2))\n",
        "        #                 #print(bij.shape)\n",
        "        #                 #print(bij)\n",
        "        #                 bi.append(bij.squeeze())\n",
        "        #             bi = torch.stack(bi)\n",
        "\n",
        "        #             bi = bi.T\n",
        "        #             #print(bi.shape)\n",
        "        #             #print(bi)\n",
        "        #             b.append(bi)\n",
        "\n",
        "\n",
        "\n",
        "        #         b = torch.stack(b)\n",
        "        #         b = b.transpose(0,1)\n",
        "\n",
        "        #         print(b)\n",
        "        #         print(b.shape)\n",
        "\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        ####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #c = F.softmax(b,dim=1)\n",
        "\n",
        "        #print(c)\n",
        "        #print(c.shape)\n",
        "        #print(0/0)\n",
        "        ############################################################\n",
        "\n",
        "        #print\n",
        "\n",
        "        #c = 32*64*17\n",
        "\n",
        "        #u_j_i = 32*768\n",
        "\n",
        "\n",
        "        #cij = 32*1\n",
        "\n",
        "\n",
        "        #         kk = []\n",
        "        #         for i in range(17):\n",
        "        #             si = 0\n",
        "        #             for j in range(64):\n",
        "        #                 #print(inputs_embeds[:,j,:].shape)\n",
        "        #                 #print(self.W_ij)\n",
        "        #                 #print(self.W_ij[i,j,:,:].shape)\n",
        "\n",
        "\n",
        "\n",
        "        #                 u_j_i = torch.mm(inputs_embeds[:,j,:],self.W_ij[i,j,:,:])\n",
        "\n",
        "\n",
        "        #                 #print(j,i,u_j_i)\n",
        "        #                 #print(0/0)\n",
        "\n",
        "        #                 cij = c[:,j,i].unsqueeze(dim=1)\n",
        "        #                 #print('cij ',cij)\n",
        "        #                 #print(cij.shape)\n",
        "        #                 #print(u_j_i)\n",
        "        #                 #print(u_j_i.shape)\n",
        "        #                 si+= u_j_i*cij\n",
        "\n",
        "        #                 #print(u_j_i*cij)\n",
        "        #             #print(si)\n",
        "        #             #print(0/0)\n",
        "\n",
        "        #             norm = torch.norm(si, dim=1)\n",
        "\n",
        "        #             #print(norm)\n",
        "        #             #print(norm.shape)\n",
        "\n",
        "        #             vi = ((norm**2)/(1+norm**2)).unsqueeze(dim=1) * (si/norm.unsqueeze(dim=1))\n",
        "\n",
        "        #             #print(vi)\n",
        "        #             kk.append(torch.norm(vi,dim=1))\n",
        "        #             #kk.append(vi)\n",
        "        #             #print(kk)\n",
        "\n",
        "\n",
        "        #         kk = torch.stack(kk)\n",
        "\n",
        "        #         print('kk', kk)\n",
        "        #         print('kk1', kk1)\n",
        "        #         print(kk.shape)\n",
        "        #         print(kk1.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vam = torch.ones((visual_attention_mask.size(0), 1), dtype=visual_attention_mask.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_attention_mask_latent = torch.cat((visual_attention_mask, ones_column_vam.to('cuda')), dim=1)\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vtt = torch.ones((visual_token_type_ids.size(0), 1), dtype=visual_token_type_ids.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_token_type_ids_latent = torch.cat((visual_token_type_ids, ones_column_vtt.to('cuda')), dim=1)\n",
        "\n",
        "        #         print(latent.shape)\n",
        "\n",
        "        #         print(visual_embeds.shape)\n",
        "        #         print(visual_attention_mask.shape)\n",
        "        #         print(visual_token_type_ids.shape)\n",
        "\n",
        "        #         print(self.w)\n",
        "\n",
        "        x = self.vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds_latent, visual_attention_mask=visual_attention_mask_latent, visual_token_type_ids=visual_token_type_ids_latent)\n",
        "\n",
        "        p = self.vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds, visual_attention_mask=visual_attention_mask, visual_token_type_ids=visual_token_type_ids)\n",
        "        p = self.grad_rev1(p.pooler_output)\n",
        "        #q = self.grad_rev2(raw_latent.repeat(B,1))\n",
        "        q = self.grad_rev2(raw_latent)\n",
        "\n",
        "        logits_p = self.linear_relu_stack_hidden(p)\n",
        "        logits_q = self.linear_relu_stack_latent(q)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        logits = self.linear_relu_stack(x.pooler_output)\n",
        "\n",
        "\n",
        "        if_logits_p = self.linear_relu_stack(p)\n",
        "        if_logits_q = self.linear_relu_stack(q)\n",
        "\n",
        "        return logits, logits_p, logits_q, if_logits_p, if_logits_q\n",
        "        #return logits, logits_p, logits_q, if_logits_p, if_logits_p\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:49.508927Z",
          "iopub.execute_input": "2024-09-21T20:30:49.509298Z",
          "iopub.status.idle": "2024-09-21T20:30:49.547109Z",
          "shell.execute_reply.started": "2024-09-21T20:30:49.509274Z",
          "shell.execute_reply": "2024-09-21T20:30:49.546311Z"
        },
        "trusted": true,
        "id": "wNmsvh2NZeXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IxPACA6mZeXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y_2PEGhKZeXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_KvGB7geZeXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bBb3XaGVZeXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dtktUp_ZeXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "vb = VB()\n",
        "\n",
        "# vb = nn.DataParallel(vb)\n",
        "vb.to(device)\n",
        "concept_classes = [\"holocaust\", \"nazism\", \"genocide\", \"funny\", \"anti muslim\", \"terrorism\", \"violence\", \"politics\", \"racism\", \"international relation\", \"adult\", \"gore\", \"misogynistic\", \"immigration\", \"extremism\", \"immoral\", \"white supremacy\", \"indecency\"]\n",
        "\n",
        "\n",
        "concept_embedding_map = {}\n",
        "\n",
        "all_concepts = []\n",
        "\n",
        "\n",
        "for c in concept_classes:\n",
        "    conc = torch.tensor(tokenizer.encode(c)[1:-1])\n",
        "    e = vb.vb.embeddings.word_embeddings(conc.to('cuda'))\n",
        "    x = e.detach().cpu().mean(dim=0)\n",
        "\n",
        "\n",
        "\n",
        "    all_concepts.append(x)\n",
        "\n",
        "    concept_embedding_map[c] = x\n",
        "\n",
        "\n",
        "all_concepts = torch.stack(all_concepts)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:49.548849Z",
          "iopub.execute_input": "2024-09-21T20:30:49.549169Z",
          "iopub.status.idle": "2024-09-21T20:30:50.478380Z",
          "shell.execute_reply.started": "2024-09-21T20:30:49.549143Z",
          "shell.execute_reply": "2024-09-21T20:30:50.477504Z"
        },
        "trusted": true,
        "id": "fV0YrHu0ZeXo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "all_concepts.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:50.480079Z",
          "iopub.execute_input": "2024-09-21T20:30:50.480402Z",
          "iopub.status.idle": "2024-09-21T20:30:50.486051Z",
          "shell.execute_reply.started": "2024-09-21T20:30:50.480375Z",
          "shell.execute_reply": "2024-09-21T20:30:50.485220Z"
        },
        "trusted": true,
        "id": "9t7BZPkmZeXp",
        "outputId": "6a560aee-6e11-47d0-d1fc-4711e7b1b7c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 44,
          "output_type": "execute_result",
          "data": {
            "text/plain": "torch.Size([18, 768])"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "#'/kaggle/working/final_model_concept.pt'\n",
        "\n",
        "vb = VB()\n",
        "vb.load_state_dict(torch.load(FILE))\n",
        "vb.to('cuda')\n",
        "vb.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:51.095000Z",
          "iopub.execute_input": "2024-09-21T20:30:51.095842Z",
          "iopub.status.idle": "2024-09-21T20:30:52.115602Z",
          "shell.execute_reply.started": "2024-09-21T20:30:51.095807Z",
          "shell.execute_reply": "2024-09-21T20:30:52.114651Z"
        },
        "trusted": true,
        "id": "PkUEwPGUZeXp",
        "outputId": "be33cccc-9b7b-4a71-f5dd-7da7e8cf840b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 45,
          "output_type": "execute_result",
          "data": {
            "text/plain": "VB(\n  (vb): VisualBertModel(\n    (embeddings): VisualBertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (visual_token_type_embeddings): Embedding(2, 768)\n      (visual_position_embeddings): Embedding(512, 768)\n      (visual_projection): Linear(in_features=2048, out_features=768, bias=True)\n    )\n    (encoder): VisualBertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x VisualBertLayer(\n          (attention): VisualBertAttention(\n            (self): VisualBertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): VisualBertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): VisualBertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): VisualBertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): VisualBertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear_relu_stack): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_latent): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_hidden): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (project_latent): Linear(in_features=768, out_features=2048, bias=True)\n  (proj_conc): Linear(in_features=768, out_features=28, bias=True)\n  (proj_embed): Linear(in_features=768, out_features=28, bias=True)\n  (grad_rev1): RevGrad()\n  (grad_rev2): RevGrad()\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all_concepts.shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:55.359277Z",
          "iopub.execute_input": "2024-09-21T20:30:55.360332Z",
          "iopub.status.idle": "2024-09-21T20:30:55.364235Z",
          "shell.execute_reply.started": "2024-09-21T20:30:55.360291Z",
          "shell.execute_reply": "2024-09-21T20:30:55.363166Z"
        },
        "trusted": true,
        "id": "cyc31sYXZeXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_concepts[0].unsqueeze(0).shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:55.800872Z",
          "iopub.execute_input": "2024-09-21T20:30:55.801729Z",
          "iopub.status.idle": "2024-09-21T20:30:55.805680Z",
          "shell.execute_reply.started": "2024-09-21T20:30:55.801693Z",
          "shell.execute_reply": "2024-09-21T20:30:55.804634Z"
        },
        "trusted": true,
        "id": "3Jr1uyCEZeXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# all_concepts[0].unsqueeze(0).repeat(32,1,1).squeeze().shape"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:56.203962Z",
          "iopub.execute_input": "2024-09-21T20:30:56.204480Z",
          "iopub.status.idle": "2024-09-21T20:30:56.209129Z",
          "shell.execute_reply.started": "2024-09-21T20:30:56.204434Z",
          "shell.execute_reply": "2024-09-21T20:30:56.208247Z"
        },
        "trusted": true,
        "id": "9auXGQaiZeXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "# check evaluation performance separately on p and q using their classifier: should be less\n",
        "pred_r1, pred_r2 = [],[]\n",
        "pred_both = []\n",
        "act = []\n",
        "for ii, batch in enumerate(eval_dataloader):\n",
        "    with torch.no_grad():\n",
        "        batch_inp = {k: v.to(device) for k, v in batch[0].items()}\n",
        "        outputs, r1, r2,_,_ = vb(all_concepts.to('cuda'),**batch_inp)\n",
        "        act.append(batch[1].detach().cpu().numpy()[0])\n",
        "\n",
        "        pred_r1.append(np.argmax(r1.detach().cpu().numpy()[0]))\n",
        "        pred_r2.append(np.argmax(r2.detach().cpu().numpy()[0]))\n",
        "        pred_both.append(np.argmax(outputs.detach().cpu().numpy()[0]))\n",
        "\n",
        "print('*')\n",
        "print(f1_score(act,pred_r1,average='macro'))\n",
        "print(f1_score(act,pred_r1,average='weighted'))\n",
        "print(accuracy_score(act,pred_r1))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_r2,average='macro'))\n",
        "print(f1_score(act,pred_r2,average='weighted'))\n",
        "print(accuracy_score(act,pred_r2))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_both,average='macro'))\n",
        "print(f1_score(act,pred_both,average='weighted'))\n",
        "print(accuracy_score(act,pred_both))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:30:56.824868Z",
          "iopub.execute_input": "2024-09-21T20:30:56.825494Z",
          "iopub.status.idle": "2024-09-21T20:31:12.506053Z",
          "shell.execute_reply.started": "2024-09-21T20:30:56.825462Z",
          "shell.execute_reply": "2024-09-21T20:31:12.505051Z"
        },
        "trusted": true,
        "id": "lXfYQ2zbZeXq",
        "outputId": "f975dde4-1aea-4a6d-b005-bc169cdfb4fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "*\n0.40647482014388486\n0.5567473294091998\n0.6848484848484848\n**********\n0.40647482014388486\n0.5567473294091998\n0.6848484848484848\n**********\n0.7036565354754966\n0.7469814601650707\n0.75\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check evaluation performance separately on p and q using parent classifier: should be also less\n",
        "pred_r1, pred_r2 = [],[]\n",
        "pred_both = []\n",
        "act = []\n",
        "for ii, batch in enumerate(eval_dataloader):\n",
        "    with torch.no_grad():\n",
        "        batch_inp = {k: v.to(device) for k, v in batch[0].items()}\n",
        "        outputs, _,_, r1, r2 = vb(all_concepts.to('cuda'),**batch_inp)\n",
        "        act.append(batch[1].detach().cpu().numpy()[0])\n",
        "\n",
        "        pred_r1.append(np.argmax(r1.detach().cpu().numpy()[0]))\n",
        "        pred_r2.append(np.argmax(r2.detach().cpu().numpy()[0]))\n",
        "        pred_both.append(np.argmax(outputs.detach().cpu().numpy()[0]))\n",
        "\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_r1,average='macro'))\n",
        "print(f1_score(act,pred_r1,average='weighted'))\n",
        "print(accuracy_score(act,pred_r1))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_r2,average='macro'))\n",
        "print(f1_score(act,pred_r2,average='weighted'))\n",
        "print(accuracy_score(act,pred_r2))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_both,average='macro'))\n",
        "print(f1_score(act,pred_both,average='weighted'))\n",
        "print(accuracy_score(act,pred_both))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:12.507735Z",
          "iopub.execute_input": "2024-09-21T20:31:12.508034Z",
          "iopub.status.idle": "2024-09-21T20:31:27.618663Z",
          "shell.execute_reply.started": "2024-09-21T20:31:12.508009Z",
          "shell.execute_reply": "2024-09-21T20:31:27.617683Z"
        },
        "trusted": true,
        "id": "Jh_nazAyZeXq",
        "outputId": "32684fe1-b871-4229-9f75-57e6d922a24d"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "**********\n0.23963133640552994\n0.1510403574919704\n0.3151515151515151\n**********\n0.23963133640552994\n0.1510403574919704\n0.3151515151515151\n**********\n0.7036565354754966\n0.7469814601650707\n0.75\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#torch.save(vb.state_dict(), '/kaggle/working/final_model_wo_adversarial.pt')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:31.935062Z",
          "iopub.execute_input": "2024-09-21T20:31:31.935438Z",
          "iopub.status.idle": "2024-09-21T20:31:31.939421Z",
          "shell.execute_reply.started": "2024-09-21T20:31:31.935408Z",
          "shell.execute_reply": "2024-09-21T20:31:31.938506Z"
        },
        "trusted": true,
        "id": "fssSWZLVZeXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "\n",
        "\n",
        "# import svm_classifier\n",
        "\n",
        "REGRESSION = False\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "def get_weights(model) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        :return: final weights of the model, as np array\n",
        "        \"\"\"\n",
        "\n",
        "        w = model.coef_\n",
        "        if len(w.shape) == 1:\n",
        "                w = np.expand_dims(w, 0)\n",
        "\n",
        "        return w\n",
        "\n",
        "\n",
        "def train_network(model, X_train: np.ndarray, Y_train: np.ndarray, X_dev: np.ndarray, Y_dev: np.ndarray) -> float:\n",
        "\n",
        "        \"\"\"\n",
        "        :param X_train:\n",
        "        :param Y_train:\n",
        "        :param X_dev:\n",
        "        :param Y_dev:\n",
        "        :return: accuracy score on the dev set / Person's R in the case of regression\n",
        "        \"\"\"\n",
        "\n",
        "        model.fit(X_train, Y_train)\n",
        "        score = model.score(X_dev, Y_dev)\n",
        "        return score\n",
        "\n",
        "\n",
        "from typing import Dict\n",
        "\n",
        "import numpy as np\n",
        "import scipy\n",
        "\n",
        "\n",
        "# import svm_classifier\n",
        "\n",
        "REGRESSION = False\n",
        "from typing import List\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "\n",
        "def get_nullspace_projection(W: np.ndarray) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    :param W: the matrix over its nullspace to project\n",
        "    :return: the projection matrix\n",
        "    \"\"\"\n",
        "    nullspace_basis = scipy.linalg.null_space(W)  # orthogonal basis\n",
        "    nullspace_basis = nullspace_basis * np.sign(nullspace_basis[0][0])  # handle sign ambiguity\n",
        "    projection_matrix = nullspace_basis.dot(nullspace_basis.T)\n",
        "\n",
        "    return projection_matrix\n",
        "\n",
        "from sklearn import svm"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:32.448693Z",
          "iopub.execute_input": "2024-09-21T20:31:32.449536Z",
          "iopub.status.idle": "2024-09-21T20:31:32.459409Z",
          "shell.execute_reply.started": "2024-09-21T20:31:32.449503Z",
          "shell.execute_reply": "2024-09-21T20:31:32.458377Z"
        },
        "trusted": true,
        "id": "Dqu8Qe4PZeXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#R\n",
        "num_concepts = 18\n",
        "BS = 8\n",
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_revgrad import RevGrad\n",
        "class VB(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(VB, self).__init__()\n",
        "        self.vb = VisualBertModel.from_pretrained(\"uclanlp/visualbert-vqa-coco-pre\")\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.linear_relu_stack_latent = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "\n",
        "        self.linear_relu_stack_hidden = nn.Sequential(\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(768, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(128, 2),\n",
        "        )\n",
        "\n",
        "        #self.w = torch.nn.Parameter(torch.ones(11,1)/11)\n",
        "        self.w = torch.nn.Parameter(torch.ones(num_concepts,1))\n",
        "\n",
        "        self.project_latent = nn.Linear(768,2048)\n",
        "\n",
        "        #self.W_ij = [[nn.Linear(768,768) for i in range(64)] for j in range(17)]\n",
        "\n",
        "        self.W_ij = torch.nn.Parameter(torch.randn(18,64,28,28))\n",
        "\n",
        "        self.proj_conc = nn.Linear(768,28)\n",
        "        self.proj_embed = nn.Linear(768,28)\n",
        "\n",
        "\n",
        "\n",
        "        self.grad_rev1 = RevGrad()\n",
        "        self.grad_rev2 = RevGrad()\n",
        "\n",
        "        self.w1 = torch.nn.Parameter(torch.tensor(0.2))\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "        all_concepts_,\n",
        "        input_ids = None,\n",
        "        attention_mask = None,\n",
        "        token_type_ids = None,\n",
        "        position_ids = None,\n",
        "        head_mask = None,\n",
        "        inputs_embeds = None,\n",
        "        visual_embeds = None,\n",
        "        visual_attention_mask = None,\n",
        "        visual_token_type_ids = None,\n",
        "        image_text_alignment = None,\n",
        "        output_attentions = None,\n",
        "        output_hidden_states = None,\n",
        "        return_dict = None):\n",
        "\n",
        "        #         print(all_concepts.shape)\n",
        "\n",
        "        B = visual_embeds.size(0)\n",
        "\n",
        "        #         print(B)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ##############################################\n",
        "\n",
        "        all_concepts = self.proj_conc(all_concepts_)\n",
        "\n",
        "\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = self.vb.embeddings.word_embeddings(input_ids)\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        inputs_embeds = self.proj_embed(inputs_embeds)\n",
        "\n",
        "\n",
        "        #####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #b1 = torch.bmm(inputs_embeds,all_concepts.repeat(B,1,1).transpose(1,2))\n",
        "\n",
        "        #print(inputs_embeds.shape)\n",
        "        #print(all_concepts.repeat(B,1,1).transpose(1,2).shape)\n",
        "\n",
        "        #b,64,28\n",
        "        #b,28,17\n",
        "\n",
        "\n",
        "        b = torch.einsum('blx,bxn->bln',inputs_embeds,all_concepts.repeat(B,1,1).transpose(1,2))\n",
        "\n",
        "        #         print(b1)\n",
        "\n",
        "        #         print('********')\n",
        "\n",
        "        #         print(b2)\n",
        "\n",
        "        #         print(torch.equal(b1,b2))\n",
        "\n",
        "\n",
        "\n",
        "        b = b.masked_fill(~attention_mask.unsqueeze(dim=2).bool(), -np.inf)\n",
        "        c = F.softmax(b,dim=1)\n",
        "\n",
        "\n",
        "\n",
        "        #inter = torch.einsum('bcsn,csnn->bcsn',inputs_embeds.unsqueeze(1).repeat(1,17,1,1), self.W_ij)\n",
        "\n",
        "        #print(inter[:,0,0,:])\n",
        "\n",
        "        einsum_expression = 'bln,clnx->bclx'\n",
        "        inter = torch.einsum(einsum_expression, inputs_embeds, self.W_ij)\n",
        "\n",
        "        k = torch.einsum('bcsn,bsc->bcn',inter,c)\n",
        "        norm = torch.norm(k,dim=2)\n",
        "\n",
        "\n",
        "\n",
        "        kk1 = ((norm**2)/(1+norm**2)).unsqueeze(dim=2) * (k/norm.unsqueeze(dim=2))\n",
        "\n",
        "        w_dynamic = kk1.norm(dim=2).unsqueeze(2)\n",
        "\n",
        "\n",
        "\n",
        "        raw_latent = (1-self.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * self.w.unsqueeze(dim=0).repeat(B,1,1) + all_concepts_.unsqueeze(0).repeat(B,1,1) * w_dynamic * self.w1\n",
        "\n",
        "\n",
        "        #raw_latent = 0 * all_concepts_.unsqueeze(0).repeat(B,1,1) * self.w.unsqueeze(dim=0).repeat(B,1,1) + all_concepts_.unsqueeze(0).repeat(B,1,1) * w_dynamic *1\n",
        "\n",
        "\n",
        "        raw_latent = torch.mean(raw_latent, dim=1)\n",
        "\n",
        "        #raw_latent = torch.mean(all_concepts*self.w,dim=0)\n",
        "        #raw_latent = raw_latent.unsqueeze(dim=0)\n",
        "\n",
        "        latent = self.project_latent(raw_latent)\n",
        "\n",
        "\n",
        "\n",
        "        latent = latent.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        visual_embeds_latent = torch.cat((visual_embeds,latent),dim=1)\n",
        "\n",
        "\n",
        "        ################################################################\n",
        "\n",
        "\n",
        "        #print(b)\n",
        "\n",
        "        #######################################################\n",
        "        #         print(b.shape)\n",
        "\n",
        "        #         b = []\n",
        "        #         for i in range(64):\n",
        "        #             bi = []\n",
        "        #             for j in range(17):\n",
        "        #                 #print(inputs_embeds[:,i,:].shape)\n",
        "        #                 ci = all_concepts[j].unsqueeze(0).repeat(32,1,1).squeeze()\n",
        "        #                 uj = inputs_embeds[:,i,:]\n",
        "        #                 #print(ci.shape)\n",
        "        #                 bij = torch.bmm(uj.unsqueeze(dim=1), ci.unsqueeze(dim=2))\n",
        "        #                 #print(bij.shape)\n",
        "        #                 #print(bij)\n",
        "        #                 bi.append(bij.squeeze())\n",
        "        #             bi = torch.stack(bi)\n",
        "\n",
        "        #             bi = bi.T\n",
        "        #             #print(bi.shape)\n",
        "        #             #print(bi)\n",
        "        #             b.append(bi)\n",
        "\n",
        "\n",
        "\n",
        "        #         b = torch.stack(b)\n",
        "        #         b = b.transpose(0,1)\n",
        "\n",
        "        #         print(b)\n",
        "        #         print(b.shape)\n",
        "\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        ####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #c = F.softmax(b,dim=1)\n",
        "\n",
        "        #print(c)\n",
        "        #print(c.shape)\n",
        "        #print(0/0)\n",
        "        ############################################################\n",
        "\n",
        "        #print\n",
        "\n",
        "        #c = 32*64*17\n",
        "\n",
        "        #u_j_i = 32*768\n",
        "\n",
        "\n",
        "        #cij = 32*1\n",
        "\n",
        "\n",
        "        #         kk = []\n",
        "        #         for i in range(17):\n",
        "        #             si = 0\n",
        "        #             for j in range(64):\n",
        "        #                 #print(inputs_embeds[:,j,:].shape)\n",
        "        #                 #print(self.W_ij)\n",
        "        #                 #print(self.W_ij[i,j,:,:].shape)\n",
        "\n",
        "\n",
        "\n",
        "        #                 u_j_i = torch.mm(inputs_embeds[:,j,:],self.W_ij[i,j,:,:])\n",
        "\n",
        "\n",
        "        #                 #print(j,i,u_j_i)\n",
        "        #                 #print(0/0)\n",
        "\n",
        "        #                 cij = c[:,j,i].unsqueeze(dim=1)\n",
        "        #                 #print('cij ',cij)\n",
        "        #                 #print(cij.shape)\n",
        "        #                 #print(u_j_i)\n",
        "        #                 #print(u_j_i.shape)\n",
        "        #                 si+= u_j_i*cij\n",
        "\n",
        "        #                 #print(u_j_i*cij)\n",
        "        #             #print(si)\n",
        "        #             #print(0/0)\n",
        "\n",
        "        #             norm = torch.norm(si, dim=1)\n",
        "\n",
        "        #             #print(norm)\n",
        "        #             #print(norm.shape)\n",
        "\n",
        "        #             vi = ((norm**2)/(1+norm**2)).unsqueeze(dim=1) * (si/norm.unsqueeze(dim=1))\n",
        "\n",
        "        #             #print(vi)\n",
        "        #             kk.append(torch.norm(vi,dim=1))\n",
        "        #             #kk.append(vi)\n",
        "        #             #print(kk)\n",
        "\n",
        "\n",
        "        #         kk = torch.stack(kk)\n",
        "\n",
        "        #         print('kk', kk)\n",
        "        #         print('kk1', kk1)\n",
        "        #         print(kk.shape)\n",
        "        #         print(kk1.shape)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vam = torch.ones((visual_attention_mask.size(0), 1), dtype=visual_attention_mask.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_attention_mask_latent = torch.cat((visual_attention_mask, ones_column_vam.to('cuda')), dim=1)\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vtt = torch.ones((visual_token_type_ids.size(0), 1), dtype=visual_token_type_ids.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_token_type_ids_latent = torch.cat((visual_token_type_ids, ones_column_vtt.to('cuda')), dim=1)\n",
        "\n",
        "        #         print(latent.shape)\n",
        "\n",
        "        #         print(visual_embeds.shape)\n",
        "        #         print(visual_attention_mask.shape)\n",
        "        #         print(visual_token_type_ids.shape)\n",
        "\n",
        "        #         print(self.w)\n",
        "\n",
        "        x = self.vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds_latent, visual_attention_mask=visual_attention_mask_latent, visual_token_type_ids=visual_token_type_ids_latent)\n",
        "\n",
        "        p = self.vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds, visual_attention_mask=visual_attention_mask, visual_token_type_ids=visual_token_type_ids)\n",
        "        p = self.grad_rev1(p.pooler_output)\n",
        "        #q = self.grad_rev2(raw_latent.repeat(B,1))\n",
        "        q = self.grad_rev2(raw_latent)\n",
        "\n",
        "        logits_p = self.linear_relu_stack_hidden(p)\n",
        "        logits_q = self.linear_relu_stack_latent(q)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        logits = self.linear_relu_stack(x.pooler_output)\n",
        "\n",
        "\n",
        "        if_logits_p = self.linear_relu_stack(p)\n",
        "        if_logits_q = self.linear_relu_stack(q)\n",
        "\n",
        "        return logits, logits_p, logits_q, if_logits_p, if_logits_q\n",
        "        #return logits, logits_p, logits_q, if_logits_p, if_logits_p\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:35.467358Z",
          "iopub.execute_input": "2024-09-21T20:31:35.467764Z",
          "iopub.status.idle": "2024-09-21T20:31:35.496457Z",
          "shell.execute_reply.started": "2024-09-21T20:31:35.467732Z",
          "shell.execute_reply": "2024-09-21T20:31:35.495523Z"
        },
        "trusted": true,
        "id": "TH_-6Y3EZeXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "def get_inlp(all_concepts):\n",
        "    print('INLP step')\n",
        "    num_concepts = 18\n",
        "    all_concepts_ = all_concepts.numpy()\n",
        "    multiplier = np.logical_xor(1, np.eye(num_concepts)).astype(np.int32)/ (num_concepts-1)\n",
        "    X = np.matmul(multiplier,all_concepts_)\n",
        "    assert X.shape[0]==num_concepts\n",
        "    Y = np.arange(num_concepts)\n",
        "\n",
        "    #             x_train_cp = x_train\n",
        "    #             x_test_cp = x_test\n",
        "    x_train_cp = X\n",
        "    x_test_cp = X\n",
        "    y_train = Y\n",
        "    y_test = Y\n",
        "    print('******')\n",
        "    for i in range(1):\n",
        "\n",
        "        clf = svm.SVC(kernel=\"linear\")\n",
        "        scr = train_network(clf, x_train_cp, y_train, x_test_cp, y_test)\n",
        "        print('initial {}'.format(scr))\n",
        "        W = get_weights(clf)\n",
        "        P_i = get_nullspace_projection(W)\n",
        "        x_train_cp = x_train_cp.dot(P_i)\n",
        "        x_test_cp = x_test_cp.dot(P_i)\n",
        "        print(clf.score(x_test_cp, y_test))\n",
        "        print(clf.score(x_train_cp, y_train))\n",
        "        clf = svm.SVC(kernel=\"linear\")\n",
        "        train_network(clf, x_train_cp, y_train, x_test_cp, y_test)\n",
        "    print('******')\n",
        "    all_concepts_ = torch.tensor(all_concepts_)\n",
        "    all_concepts_ = all_concepts_.mm(torch.tensor(P_i, dtype = all_concepts_.dtype))\n",
        "\n",
        "    return all_concepts_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:37.586043Z",
          "iopub.execute_input": "2024-09-21T20:31:37.586707Z",
          "iopub.status.idle": "2024-09-21T20:31:37.596049Z",
          "shell.execute_reply.started": "2024-09-21T20:31:37.586675Z",
          "shell.execute_reply": "2024-09-21T20:31:37.595051Z"
        },
        "trusted": true,
        "id": "jk2QGK7MZeXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "import torch\n",
        "from torch import nn\n",
        "from pytorch_revgrad import RevGrad\n",
        "class VB_wrapper(nn.Module):\n",
        "    def __init__(self, vb):\n",
        "        super(VB_wrapper, self).__init__()\n",
        "\n",
        "        self.vb = vb\n",
        "\n",
        "\n",
        "\n",
        "    def forward(self,\n",
        "        all_concepts_,\n",
        "        input_embeds = None,\n",
        "        visual_embeds = None,\n",
        "        attention_mask = None,\n",
        "        token_type_ids = None,\n",
        "        position_ids = None,\n",
        "        head_mask = None,\n",
        "        inputs_embeds = None,\n",
        "\n",
        "        visual_attention_mask = None,\n",
        "        visual_token_type_ids = None,\n",
        "        image_text_alignment = None,\n",
        "        output_attentions = None,\n",
        "        output_hidden_states = None,\n",
        "        return_dict = None):\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #         print('ac', all_concepts_.shape)\n",
        "        #         print('ii', input_embeds.shape)\n",
        "        #         print('am', attention_mask)\n",
        "        #         print('tti', token_type_ids)\n",
        "        #         print('pi', position_ids)\n",
        "        #         print('hm', head_mask)\n",
        "        #         print('ie', inputs_embeds)\n",
        "        #         print('ve', visual_embeds)\n",
        "        #         print('vam', visual_attention_mask)\n",
        "        #         print('vtti', visual_token_type_ids)\n",
        "        #         print(image_text_alignment)\n",
        "        #         print(output_attentions)\n",
        "        #         print(output_hidden_states)\n",
        "        #         print(return_dict)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        B = visual_embeds.size(0)\n",
        "\n",
        "\n",
        "        all_concepts = self.vb.proj_conc(all_concepts_)\n",
        "\n",
        "\n",
        "\n",
        "        \"\"\"\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = self.vb.vb.embeddings.word_embeddings(input_ids.to('cuda'))\n",
        "        \"\"\"\n",
        "\n",
        "        with torch.no_grad():\n",
        "            inputs_embeds = self.vb.vb.embeddings.word_embeddings(input_ids.to('cuda'))\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        inputs_embeds = self.vb.proj_embed(inputs_embeds)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        b = torch.einsum('blx,bxn->bln',inputs_embeds,all_concepts.transpose(1,2))\n",
        "\n",
        "\n",
        "        #print(b.shape)\n",
        "\n",
        "\n",
        "\n",
        "        b = b.masked_fill(~attention_mask.unsqueeze(dim=2).bool(), -np.inf)\n",
        "        c = F.softmax(b,dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        einsum_expression = 'bln,clnx->bclx'\n",
        "        inter = torch.einsum(einsum_expression, inputs_embeds, self.vb.W_ij)\n",
        "\n",
        "        k = torch.einsum('bcsn,bsc->bcn',inter,c)\n",
        "        norm = torch.norm(k,dim=2)\n",
        "\n",
        "\n",
        "\n",
        "        kk1 = ((norm**2)/(1+norm**2)).unsqueeze(dim=2) * (k/norm.unsqueeze(dim=2))\n",
        "\n",
        "        w_dynamic = kk1.norm(dim=2).unsqueeze(2)\n",
        "\n",
        "        num_reps = int(all_concepts.shape[0])\n",
        "        w_static = self.vb.w.unsqueeze(0).repeat(num_reps,1,1)\n",
        "\n",
        "\n",
        "        #         print('*'*10)\n",
        "\n",
        "        #         print(self.vb.w1.shape)\n",
        "        #         print(all_concepts_.shape)\n",
        "        #         print(w_static.shape)\n",
        "        #         print(w_dynamic.shape)\n",
        "\n",
        "\n",
        "\n",
        "        if DYN_ROUTE:\n",
        "            raw_latent = (1-self.vb.w1) * all_concepts_ * w_static + all_concepts_ * w_dynamic * self.vb.w1\n",
        "\n",
        "        else:\n",
        "            raw_latent = (1-self.vb.w1) * all_concepts_ * w_static\n",
        "\n",
        "\n",
        "\n",
        "        #raw_latent = (1-self.vb.w1) * all_concepts_ * w_static\n",
        "        raw_latent = torch.mean(raw_latent, dim=1)\n",
        "\n",
        "\n",
        "        latent = self.vb.project_latent(raw_latent)\n",
        "\n",
        "\n",
        "\n",
        "        latent = latent.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        visual_embeds_latent = torch.cat((visual_embeds,latent),dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        #         num_reps = int(all_concepts.shape[0]/17)\n",
        "        #         w_static = self.vb.w.unsqueeze(0).repeat(num_reps,1,1).reshape(17*num_reps,1)\n",
        "        #         raw_latent = torch.mean(all_concepts*w_static,dim=0)\n",
        "        #         raw_latent = raw_latent.unsqueeze(dim=0)\n",
        "\n",
        "        #         latent = self.vb.project_latent(raw_latent)\n",
        "\n",
        "\n",
        "\n",
        "        #         latent = latent.repeat(B,1).unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "        #         visual_embeds_latent = torch.cat((visual_embeds,latent),dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vam = torch.ones((visual_attention_mask.size(0), 1), dtype=visual_attention_mask.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_attention_mask_latent = torch.cat((visual_attention_mask, ones_column_vam.to('cuda')), dim=1)\n",
        "\n",
        "        # Create a tensor of ones with the same number of columns as the original tensor\n",
        "        ones_column_vtt = torch.ones((visual_token_type_ids.size(0), 1), dtype=visual_token_type_ids.dtype)\n",
        "\n",
        "        # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "        visual_token_type_ids_latent = torch.cat((visual_token_type_ids, ones_column_vtt.to('cuda')), dim=1)\n",
        "\n",
        "        #         print(latent.shape)\n",
        "\n",
        "        #         print(visual_embeds.shape)\n",
        "        #         print(visual_attention_mask.shape)\n",
        "        #         print(visual_token_type_ids.shape)\n",
        "\n",
        "        #         print(self.w)\n",
        "\n",
        "        x = self.vb.vb(inputs_embeds = input_embeds, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds_latent, visual_attention_mask=visual_attention_mask_latent, visual_token_type_ids=visual_token_type_ids_latent)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        logits = self.vb.linear_relu_stack(x.pooler_output)\n",
        "        #print('softmax logit', torch.softmax(logits, dim=1))\n",
        "        #print(0/0)\n",
        "\n",
        "        #logits = torch.softmax(logits, dim=1)[:, 1].unsqueeze(1)\n",
        "\n",
        "        #print('previous',torch.softmax(logits, dim=1)[:, 1].unsqueeze(1) )\n",
        "\n",
        "        logits = torch.softmax(logits, dim=1).max(dim=1).values.unsqueeze(1)\n",
        "\n",
        "        #print('logits', logits)\n",
        "\n",
        "        #print(0/0)\n",
        "\n",
        "        #print(logits)\n",
        "        #print(logits.shape)\n",
        "\n",
        "\n",
        "\n",
        "        return logits\n",
        "\n",
        ""
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:39.431621Z",
          "iopub.execute_input": "2024-09-21T20:31:39.431999Z",
          "iopub.status.idle": "2024-09-21T20:31:39.452345Z",
          "shell.execute_reply.started": "2024-09-21T20:31:39.431972Z",
          "shell.execute_reply": "2024-09-21T20:31:39.451360Z"
        },
        "trusted": true,
        "id": "OL6Y2UG7ZeXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "#'/kaggle/working/final_model_concept.pt'\n",
        "\n",
        "vb = VB()\n",
        "\n",
        "vb.load_state_dict(torch.load(FILE))\n",
        "vb.to('cuda')\n",
        "vb.eval()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:41.315217Z",
          "iopub.execute_input": "2024-09-21T20:31:41.315594Z",
          "iopub.status.idle": "2024-09-21T20:31:42.351016Z",
          "shell.execute_reply.started": "2024-09-21T20:31:41.315559Z",
          "shell.execute_reply": "2024-09-21T20:31:42.350024Z"
        },
        "trusted": true,
        "id": "8yDtgm76ZeXs",
        "outputId": "e7f59fd4-f076-4bf9-8d54-f903b9fcc74d"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 56,
          "output_type": "execute_result",
          "data": {
            "text/plain": "VB(\n  (vb): VisualBertModel(\n    (embeddings): VisualBertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (visual_token_type_embeddings): Embedding(2, 768)\n      (visual_position_embeddings): Embedding(512, 768)\n      (visual_projection): Linear(in_features=2048, out_features=768, bias=True)\n    )\n    (encoder): VisualBertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x VisualBertLayer(\n          (attention): VisualBertAttention(\n            (self): VisualBertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): VisualBertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): VisualBertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): VisualBertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): VisualBertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear_relu_stack): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_latent): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_hidden): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (project_latent): Linear(in_features=768, out_features=2048, bias=True)\n  (proj_conc): Linear(in_features=768, out_features=28, bias=True)\n  (proj_embed): Linear(in_features=768, out_features=28, bias=True)\n  (grad_rev1): RevGrad()\n  (grad_rev2): RevGrad()\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "vb_c = VB()\n",
        "vb_c.to(device)\n",
        "# concept_classes = [\"jew\", \"holocaust\", \"hitler\", \"genocide\", \"funny\", \"muslim\", \"terrorism\", \"violence\", \"politics\", \"naive\", \"international relation\"]\n",
        "\n",
        "\n",
        "# concept_embedding_map = {}\n",
        "\n",
        "# all_concepts = []\n",
        "\n",
        "\n",
        "# for c in concept_classes:\n",
        "#     conc = torch.tensor(tokenizer.encode(c)[1:-1])\n",
        "#     e = vb_c.vb.embeddings.word_embeddings(conc.to('cuda'))\n",
        "#     x = e.detach().cpu().mean(dim=0)\n",
        "\n",
        "#     all_concepts.append(x)\n",
        "\n",
        "#     concept_embedding_map[c] = x\n",
        "\n",
        "\n",
        "# all_concepts = torch.stack(all_concepts)\n",
        "\n",
        "# concept_classes = [\"jew\", \"holocaust\", \"hitler\", \"genocide\", \"funny\", \"muslim\", \"terrorism\", \"violence\", \"politics\", \"racism\", \"international relation\", \"sex\", \"gore\", \"violence\", \"immigration\", \"extremism\", \"immoral\"]\n",
        "\n",
        "concept_classes = [\"holocaust\", \"nazism\", \"genocide\", \"funny\", \"anti muslim\", \"terrorism\", \"violence\", \"politics\", \"racism\", \"international relation\", \"adult\", \"gore\", \"misogynistic\", \"immigration\", \"extremism\", \"immoral\", \"white supremacy\", \"indecency\"]\n",
        "\n",
        "\n",
        "concept_embedding_map = {}\n",
        "\n",
        "all_concepts = []\n",
        "\n",
        "\n",
        "for c in concept_classes:\n",
        "    conc = torch.tensor(tokenizer.encode(c)[1:-1])\n",
        "    e = vb_c.vb.embeddings.word_embeddings(conc.to('cuda'))\n",
        "    x = e.detach().cpu().mean(dim=0)\n",
        "\n",
        "\n",
        "    all_concepts.append(x)\n",
        "\n",
        "    concept_embedding_map[c] = x\n",
        "\n",
        "\n",
        "all_concepts = torch.stack(all_concepts)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:43.136935Z",
          "iopub.execute_input": "2024-09-21T20:31:43.137316Z",
          "iopub.status.idle": "2024-09-21T20:31:43.794902Z",
          "shell.execute_reply.started": "2024-09-21T20:31:43.137287Z",
          "shell.execute_reply": "2024-09-21T20:31:43.794109Z"
        },
        "trusted": true,
        "id": "R2SuRtRsZeXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "def get_inlp(all_concepts):\n",
        "\n",
        "    num_concepts = 18\n",
        "    all_concepts_ = all_concepts.cpu().numpy()\n",
        "    multiplier = np.logical_xor(1, np.eye(num_concepts)).astype(np.int32)/ (num_concepts-1)\n",
        "    X = np.matmul(multiplier,all_concepts_)\n",
        "    assert X.shape[0]==num_concepts\n",
        "    Y = np.arange(num_concepts)\n",
        "\n",
        "    #             x_train_cp = x_train\n",
        "    #             x_test_cp = x_test\n",
        "    x_train_cp = X\n",
        "    x_test_cp = X\n",
        "    y_train = Y\n",
        "    y_test = Y\n",
        "\n",
        "    for i in range(1):\n",
        "\n",
        "        clf = svm.SVC(kernel=\"linear\")\n",
        "        scr = train_network(clf, x_train_cp, y_train, x_test_cp, y_test)\n",
        "\n",
        "        W = get_weights(clf)\n",
        "        P_i = get_nullspace_projection(W)\n",
        "        x_train_cp = x_train_cp.dot(P_i)\n",
        "        x_test_cp = x_test_cp.dot(P_i)\n",
        "\n",
        "        clf = svm.SVC(kernel=\"linear\")\n",
        "        train_network(clf, x_train_cp, y_train, x_test_cp, y_test)\n",
        "\n",
        "    all_concepts_ = torch.tensor(all_concepts_)\n",
        "    all_concepts_ = all_concepts_.mm(torch.tensor(P_i, dtype = all_concepts_.dtype))\n",
        "\n",
        "    return all_concepts_"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:44.328859Z",
          "iopub.execute_input": "2024-09-21T20:31:44.329243Z",
          "iopub.status.idle": "2024-09-21T20:31:44.337959Z",
          "shell.execute_reply.started": "2024-09-21T20:31:44.329202Z",
          "shell.execute_reply": "2024-09-21T20:31:44.336959Z"
        },
        "trusted": true,
        "id": "1TUZBw-tZeXt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "#torch.save(vb.state_dict(), '/kaggle/working/final_model_concept_inlp.pt')\n",
        "# check evaluation performance separately on p and q using their classifier: should be less\n",
        "pred_r1, pred_r2 = [],[]\n",
        "pred_both = []\n",
        "act = []\n",
        "if DECONFOUND:\n",
        "    all_concepts_ = get_inlp(all_concepts).to('cuda')\n",
        "else:\n",
        "    all_concepts_ = all_concepts.to('cuda')\n",
        "\n",
        "for ii, batch in enumerate(eval_dataloader):\n",
        "    with torch.no_grad():\n",
        "        batch_inp = {k: v.to(device) for k, v in batch[0].items()}\n",
        "        outputs, r1, r2,_,_ = vb(all_concepts_.to('cuda'),**batch_inp)\n",
        "        act.append(batch[1].detach().cpu().numpy()[0])\n",
        "\n",
        "        pred_r1.append(np.argmax(r1.detach().cpu().numpy()[0]))\n",
        "        pred_r2.append(np.argmax(r2.detach().cpu().numpy()[0]))\n",
        "        pred_both.append(np.argmax(outputs.detach().cpu().numpy()[0]))\n",
        "\n",
        "print('*')\n",
        "print(f1_score(act,pred_r1,average='macro'))\n",
        "print(f1_score(act,pred_r1,average='weighted'))\n",
        "print(accuracy_score(act,pred_r1))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_r2,average='macro'))\n",
        "print(f1_score(act,pred_r2,average='weighted'))\n",
        "print(accuracy_score(act,pred_r2))\n",
        "print('*'*10)\n",
        "print(f1_score(act,pred_both,average='macro'))\n",
        "print(f1_score(act,pred_both,average='weighted'))\n",
        "print(accuracy_score(act,pred_both))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:31:45.873967Z",
          "iopub.execute_input": "2024-09-21T20:31:45.874850Z",
          "iopub.status.idle": "2024-09-21T20:32:01.230994Z",
          "shell.execute_reply.started": "2024-09-21T20:31:45.874817Z",
          "shell.execute_reply": "2024-09-21T20:32:01.230082Z"
        },
        "trusted": true,
        "id": "A3FVMIt-ZeXt",
        "outputId": "e758a566-cdc7-4d78-e154-59a46f9a41fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "*\n0.40647482014388486\n0.5567473294091998\n0.6848484848484848\n**********\n0.40647482014388486\n0.5567473294091998\n0.6848484848484848\n**********\n0.7036565354754966\n0.7469814601650707\n0.75\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('h')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:01.232594Z",
          "iopub.execute_input": "2024-09-21T20:32:01.232886Z",
          "iopub.status.idle": "2024-09-21T20:32:01.237574Z",
          "shell.execute_reply.started": "2024-09-21T20:32:01.232861Z",
          "shell.execute_reply": "2024-09-21T20:32:01.236526Z"
        },
        "trusted": true,
        "id": "Suylu-2gZeXt",
        "outputId": "0acac907-890c-445e-dded-544ddb16b7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "h\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "def model_pred(input_ids, attention_mask, token_type_ids, visual_embeds, visual_attention_mask, visual_token_type_ids, all_concepts, concept_no=None):\n",
        "\n",
        "\n",
        "\n",
        "    B = visual_embeds.size(0)\n",
        "\n",
        "\n",
        "    #######################################################\n",
        "    input_ids = input_ids.to('cuda')\n",
        "    attention_mask = attention_mask.to('cuda')\n",
        "    token_type_ids = token_type_ids.to('cuda')\n",
        "    visual_embeds = visual_embeds.to('cuda')\n",
        "    visual_attention_mask = visual_attention_mask.to('cuda')\n",
        "    visual_token_type_ids = visual_token_type_ids.to('cuda')\n",
        "\n",
        "    #####################################################################\n",
        "\n",
        "    ##############################################\n",
        "\n",
        "    all_concepts = all_concepts.to('cuda')\n",
        "\n",
        "    # deconfounding step by passing the concepts through INLP (1)\n",
        "    if DECONFOUND:\n",
        "        all_concepts_ = get_inlp(all_concepts).to('cuda')\n",
        "    else:\n",
        "        all_concepts_ = all_concepts.to('cuda')\n",
        "\n",
        "    # this is without deconfounding while testing (2)\n",
        "    # either use (1) or (2) or mean of (1) and (2)\n",
        "\n",
        "    # all_concepts_ = all_concepts.to('cuda')\n",
        "\n",
        "    #all_concepts_ = (get_inlp(all_concepts).to('cuda') + all_concepts.to('cuda')) / 2\n",
        "\n",
        "    all_concepts = vb.proj_conc(all_concepts_)\n",
        "\n",
        "\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs_embeds = vb.vb.embeddings.word_embeddings(input_ids.to('cuda'))\n",
        "\n",
        "    #print(0/0)\n",
        "\n",
        "    inputs_embeds = vb.proj_embed(inputs_embeds)\n",
        "\n",
        "\n",
        "    #####################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    #B, 64, 28, #B, 28, 17\n",
        "\n",
        "    b = torch.einsum('blx,bxn->bln',inputs_embeds,all_concepts.repeat(B,1,1).transpose(1,2))\n",
        "\n",
        "\n",
        "\n",
        "    b = b.masked_fill(~attention_mask.unsqueeze(dim=2).bool(), -np.inf)\n",
        "    c = F.softmax(b,dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    einsum_expression = 'bln,clnx->bclx'\n",
        "    inter = torch.einsum(einsum_expression, inputs_embeds, vb.W_ij)\n",
        "\n",
        "    k = torch.einsum('bcsn,bsc->bcn',inter,c)\n",
        "    norm = torch.norm(k,dim=2)\n",
        "\n",
        "\n",
        "\n",
        "    kk1 = ((norm**2)/(1+norm**2)).unsqueeze(dim=2) * (k/norm.unsqueeze(dim=2))\n",
        "\n",
        "    w_dynamic = kk1.norm(dim=2).unsqueeze(2)\n",
        "\n",
        "    #     print(w_dynamic.shape)\n",
        "    #     print(vb.w.shape)\n",
        "\n",
        "\n",
        "    #     print(w_dynamic)\n",
        "    #     print(vb.w)\n",
        "    #     print('*'*10)\n",
        "\n",
        "\n",
        "    #print(concept_no)\n",
        "    if concept_no==None:\n",
        "        k_static = vb.w.data.clone()\n",
        "        k_dynamic = w_dynamic.data.clone()\n",
        "    else:\n",
        "        k_static = vb.w.data.clone()\n",
        "        k_dynamic = w_dynamic.data.clone()\n",
        "        k_static[concept_no][0] = 0\n",
        "        k_dynamic[0][concept_no][0] = 0\n",
        "\n",
        "    #     print(k_dynamic)\n",
        "    #     print(k_static)\n",
        "    #     print('*'*10)\n",
        "\n",
        "    #     print(0/0)\n",
        "\n",
        "    #either use the following line or raw_latent = (1-vb.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * k_static.unsqueeze(dim=0).repeat(B,1,1)\n",
        "\n",
        "    if DYN_ROUTE:\n",
        "        raw_latent = (1-vb.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * k_static.unsqueeze(dim=0).repeat(B,1,1) + all_concepts_.unsqueeze(0).repeat(B,1,1) * k_dynamic * vb.w1\n",
        "    else:\n",
        "        raw_latent = (1-vb.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * k_static.unsqueeze(dim=0).repeat(B,1,1)\n",
        "\n",
        "    #raw_latent = 0.0 * all_concepts_.unsqueeze(0).repeat(B,1,1) * k_static.unsqueeze(dim=0).repeat(B,1,1) + all_concepts_.unsqueeze(0).repeat(B,1,1) * k_dynamic * 1.0\n",
        "\n",
        "    #raw_latent = (1-vb.w1) * all_concepts_.unsqueeze(0).repeat(B,1,1) * k_static.unsqueeze(dim=0).repeat(B,1,1)\n",
        "\n",
        "    raw_latent = torch.mean(raw_latent, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    latent = vb.project_latent(raw_latent)\n",
        "\n",
        "\n",
        "\n",
        "    latent = latent.unsqueeze(dim=1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    visual_embeds_latent = torch.cat((visual_embeds,latent),dim=1)\n",
        "\n",
        "\n",
        "    ################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Create a tensor of ones with the same number of columns as the original tensor\n",
        "    ones_column_vam = torch.ones((visual_attention_mask.size(0), 1), dtype=visual_attention_mask.dtype)\n",
        "\n",
        "    # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "    visual_attention_mask_latent = torch.cat((visual_attention_mask.to('cuda'), ones_column_vam.to('cuda')), dim=1)\n",
        "\n",
        "    # Create a tensor of ones with the same number of columns as the original tensor\n",
        "    ones_column_vtt = torch.ones((visual_token_type_ids.size(0), 1), dtype=visual_token_type_ids.dtype)\n",
        "\n",
        "    # Concatenate the original tensor with the tensor of ones along the second dimension (columns)\n",
        "    visual_token_type_ids_latent = torch.cat((visual_token_type_ids.to('cuda'), ones_column_vtt.to('cuda')), dim=1)\n",
        "\n",
        "\n",
        "\n",
        "    x = vb.vb(input_ids = input_ids.to('cuda'), token_type_ids = token_type_ids.to('cuda'), attention_mask = attention_mask.to('cuda'), visual_embeds=visual_embeds_latent.to('cuda'), visual_attention_mask=visual_attention_mask_latent.to('cuda'), visual_token_type_ids=visual_token_type_ids_latent.to('cuda'))\n",
        "\n",
        "    p = vb.vb(input_ids = input_ids.to('cuda'), token_type_ids = token_type_ids.to('cuda'), attention_mask = attention_mask.to('cuda'), visual_embeds=visual_embeds.to('cuda'), visual_attention_mask=visual_attention_mask.to('cuda'), visual_token_type_ids=visual_token_type_ids.to('cuda'))\n",
        "    p = vb.grad_rev1(p.pooler_output)\n",
        "    q = vb.grad_rev2(raw_latent.repeat(B,1))\n",
        "\n",
        "    logits_p = vb.linear_relu_stack_hidden(p)\n",
        "    logits_q = vb.linear_relu_stack_latent(q.to('cuda'))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    logits = vb.linear_relu_stack(x.pooler_output)\n",
        "\n",
        "\n",
        "    if_logits_p = vb.linear_relu_stack(p)\n",
        "    if_logits_q = vb.linear_relu_stack(q.to('cuda'))\n",
        "\n",
        "    return torch.softmax(logits,dim=-1), x.pooler_output"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:01.238781Z",
          "iopub.execute_input": "2024-09-21T20:32:01.239054Z",
          "iopub.status.idle": "2024-09-21T20:32:01.262327Z",
          "shell.execute_reply.started": "2024-09-21T20:32:01.239020Z",
          "shell.execute_reply": "2024-09-21T20:32:01.261541Z"
        },
        "trusted": true,
        "id": "Z6Yx4XOkZeXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:01.265140Z",
          "iopub.execute_input": "2024-09-21T20:32:01.265676Z",
          "iopub.status.idle": "2024-09-21T20:32:01.279020Z",
          "shell.execute_reply.started": "2024-09-21T20:32:01.265651Z",
          "shell.execute_reply": "2024-09-21T20:32:01.278213Z"
        },
        "trusted": true,
        "id": "ytc6egHoZeXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(50):\n",
        "    if train_set[i]['label']==1:\n",
        "        print(i, train_set[i])\n",
        "        Image.open('/kaggle/input/facebook-hateful-meme-dataset/data/'+train_set[i]['img'])\n",
        "        inputs = {}\n",
        "        inputs = tokenizer(train_set[i]['text'], padding=\"max_length\", truncation=True, max_length=64, return_tensors='pt')\n",
        "\n",
        "\n",
        "        inputs['input_ids'] = inputs['input_ids']\n",
        "        inputs['token_type_ids'] = inputs['token_type_ids']\n",
        "        inputs['attention_mask'] = inputs['attention_mask']\n",
        "\n",
        "        input_ids = inputs['input_ids']\n",
        "        token_type_ids = inputs['token_type_ids']\n",
        "        attention_mask = inputs['attention_mask']\n",
        "\n",
        "        visual_embeds,visual_token_type_ids,visual_attention_mask = get_visual_embedding('/kaggle/input/facebook-hateful-meme-dataset/data/'+train_set[i]['img'])\n",
        "        # visual_embeds,visual_token_type_ids,visual_attention_mask = visual_feats[train_set[874]['img']]\n",
        "\n",
        "\n",
        "\n",
        "        inputs.update({\n",
        "          \"visual_embeds\":  visual_embeds,\n",
        "          \"visual_token_type_ids\": visual_token_type_ids,\n",
        "          \"visual_attention_mask\": visual_attention_mask\n",
        "        })\n",
        "\n",
        "\n",
        "        class_map = {0:'non offensive', 1: 'offensive'}\n",
        "        #print('original model prediction {}'.format(model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids)))\n",
        "        orig,_ = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts)\n",
        "        orig = orig[0]\n",
        "        print(orig)\n",
        "        print('predicted class {}'.format(class_map[np.argmax(orig.detach().cpu().numpy())]))\n",
        "        pred_class = np.argmax(orig.detach().cpu().numpy())\n",
        "        orig = orig[pred_class]\n",
        "\n",
        "        k = []\n",
        "        for i in range(18):\n",
        "            #print('Removing concept: {}'.format(concept_classes[i]))\n",
        "\n",
        "            after_intervention,_ = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts,concept_no=i)\n",
        "            #print('hello')\n",
        "            after_intervention = after_intervention[0][pred_class]\n",
        "            #print(after_intervention, orig)\n",
        "            #print(0/0)\n",
        "            k.append(abs(after_intervention-orig).item())\n",
        "            #print('model prediction after removal {}'.format(model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,concept_no=i)))\n",
        "        k = np.asarray(k)\n",
        "        print(k)\n",
        "        k = list(map(lambda x: ((x-np.mean(k))/np.mean(k))*100, k))\n",
        "\n",
        "        conc_scr = []\n",
        "        for i in range(17):\n",
        "            cc = concept_classes[i]\n",
        "            print('relative ICaCE scores for concept {} is {}%'.format(cc,k[i]))\n",
        "            conc_scr.append((cc,k[i]))\n",
        "        conc_scr.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "        for i in conc_scr:\n",
        "            if i[1]> 0:\n",
        "                print(i[0], end = \" \")\n",
        "        print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:01.280273Z",
          "iopub.execute_input": "2024-09-21T20:32:01.280535Z",
          "iopub.status.idle": "2024-09-21T20:32:14.382691Z",
          "shell.execute_reply.started": "2024-09-21T20:32:01.280513Z",
          "shell.execute_reply": "2024-09-21T20:32:14.381537Z"
        },
        "trusted": true,
        "id": "kYZw1AJfZeXu",
        "outputId": "94f011c0-f948-461a-c49d-ee45c671b6cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "10 {'text': 'jew mad? get fuhrerious!', 'img': 'img/79351.png', 'label': 1}\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/site-packages/torch/functional.py:504: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3526.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "tensor([0.2246, 0.7754], device='cuda:0', grad_fn=<SelectBackward0>)\npredicted class offensive\n[0.00029802 0.00029796 0.00029647 0.0002957  0.0002982  0.00029802\n 0.0002982  0.0002982  0.00029701 0.00029832 0.0002982  0.00029796\n 0.00029808 0.00029701 0.00029755 0.00029844 0.00029582 0.00029677]\nrelative ICaCE scores for concept holocaust is 0.15802710943933357%\nrelative ICaCE scores for concept nazism is 0.1379955040174457%\nrelative ICaCE scores for concept genocide is -0.362794631529751%\nrelative ICaCE scores for concept funny is -0.6232055020142933%\nrelative ICaCE scores for concept anti muslim is 0.21812192570499714%\nrelative ICaCE scores for concept terrorism is 0.15802710943933357%\nrelative ICaCE scores for concept violence is 0.21812192570499714%\nrelative ICaCE scores for concept politics is 0.21812192570499714%\nrelative ICaCE scores for concept racism is -0.18251018273276015%\nrelative ICaCE scores for concept international relation is 0.2581851365487729%\nrelative ICaCE scores for concept adult is 0.21812192570499714%\nrelative ICaCE scores for concept gore is 0.1379955040174457%\nrelative ICaCE scores for concept misogynistic is 0.17805871486122143%\nrelative ICaCE scores for concept immigration is -0.18251018273276015%\nrelative ICaCE scores for concept extremism is -0.002225733935769367%\nrelative ICaCE scores for concept immoral is 0.29824834739254863%\nrelative ICaCE scores for concept white supremacy is -0.5831422911705175%\nimmoral international relation anti muslim violence politics adult misogynistic holocaust terrorism nazism gore \n\n12 {'text': 'brother... a day without a blast is a day wasted', 'img': 'img/25489.png', 'label': 1}\ntensor([0.8937, 0.1063], device='cuda:0', grad_fn=<SelectBackward0>)\npredicted class non offensive\n[0.00020522 0.0002057  0.0002057  0.00020552 0.00020534 0.0002057\n 0.00020558 0.00020558 0.00020534 0.0002057  0.00020552 0.00020558\n 0.00020534 0.0002057  0.00020552 0.0002057  0.00020552 0.00020558]\nrelative ICaCE scores for concept holocaust is -0.15788117025389575%\nrelative ICaCE scores for concept nazism is 0.07410748807836355%\nrelative ICaCE scores for concept genocide is 0.07410748807836355%\nrelative ICaCE scores for concept funny is -0.012888258796233697%\nrelative ICaCE scores for concept anti muslim is -0.09988400567083094%\nrelative ICaCE scores for concept terrorism is 0.07410748807836355%\nrelative ICaCE scores for concept violence is 0.016110323495298718%\nrelative ICaCE scores for concept politics is 0.016110323495298718%\nrelative ICaCE scores for concept racism is -0.09988400567083094%\nrelative ICaCE scores for concept international relation is 0.07410748807836355%\nrelative ICaCE scores for concept adult is -0.012888258796233697%\nrelative ICaCE scores for concept gore is 0.016110323495298718%\nrelative ICaCE scores for concept misogynistic is -0.09988400567083094%\nrelative ICaCE scores for concept immigration is 0.07410748807836355%\nrelative ICaCE scores for concept extremism is -0.012888258796233697%\nrelative ICaCE scores for concept immoral is 0.07410748807836355%\nrelative ICaCE scores for concept white supremacy is -0.012888258796233697%\nnazism genocide terrorism international relation immigration immoral violence politics gore \n\n27 {'text': \"is bribing muslims for liberal votes justin trudeau's only skill? why does justin trudeau love foreigners so much while openly disrespecting canadians, canadian values, our history and traditions, our seniors and veterans? sharia law has no place in canada! never has... never will.\", 'img': 'img/72640.png', 'label': 1}\ntensor([0.1694, 0.8306], device='cuda:0', grad_fn=<SelectBackward0>)\npredicted class offensive\n[7.15255737e-07 7.15255737e-07 7.15255737e-07 7.15255737e-07\n 7.15255737e-07 7.15255737e-07 7.15255737e-07 7.15255737e-07\n 7.15255737e-07 7.74860382e-07 7.15255737e-07 7.15255737e-07\n 7.15255737e-07 7.15255737e-07 7.74860382e-07 7.15255737e-07\n 7.15255737e-07 7.15255737e-07]\nrelative ICaCE scores for concept holocaust is -0.9174311926605472%\nrelative ICaCE scores for concept nazism is -0.9174311926605472%\nrelative ICaCE scores for concept genocide is -0.9174311926605472%\nrelative ICaCE scores for concept funny is -0.9174311926605472%\nrelative ICaCE scores for concept anti muslim is -0.9174311926605472%\nrelative ICaCE scores for concept terrorism is -0.9174311926605472%\nrelative ICaCE scores for concept violence is -0.9174311926605472%\nrelative ICaCE scores for concept politics is -0.9174311926605472%\nrelative ICaCE scores for concept racism is -0.9174311926605472%\nrelative ICaCE scores for concept international relation is 7.339449541284407%\nrelative ICaCE scores for concept adult is -0.9174311926605472%\nrelative ICaCE scores for concept gore is -0.9174311926605472%\nrelative ICaCE scores for concept misogynistic is -0.9174311926605472%\nrelative ICaCE scores for concept immigration is -0.9174311926605472%\nrelative ICaCE scores for concept extremism is 7.339449541284407%\nrelative ICaCE scores for concept immoral is -0.9174311926605472%\nrelative ICaCE scores for concept white supremacy is -0.9174311926605472%\ninternational relation extremism \n\n30 {'text': \"d.j. osama spin laden droppin' beats like the twin towers\", 'img': 'img/93547.png', 'label': 1}\ntensor([0.2857, 0.7143], device='cuda:0', grad_fn=<SelectBackward0>)\npredicted class offensive\n[0.00069511 0.00069517 0.00069755 0.00069517 0.00069827 0.00069535\n 0.00069821 0.00069696 0.00069648 0.00069809 0.00069487 0.00069636\n 0.00069779 0.0006966  0.00069463 0.00069839 0.00069684 0.00069678]\nrelative ICaCE scores for concept holocaust is -0.21248983899260368%\nrelative ICaCE scores for concept nazism is -0.2039332011808212%\nrelative ICaCE scores for concept genocide is 0.1383323112904784%\nrelative ICaCE scores for concept funny is -0.2039332011808212%\nrelative ICaCE scores for concept anti muslim is 0.24101196503186825%\nrelative ICaCE scores for concept terrorism is -0.17826328774547373%\nrelative ICaCE scores for concept violence is 0.23245532722008577%\nrelative ICaCE scores for concept politics is 0.052765933172653504%\nrelative ICaCE scores for concept racism is -0.01568716932160642%\nrelative ICaCE scores for concept international relation is 0.2153420515965208%\nrelative ICaCE scores for concept adult is -0.24671639023973366%\nrelative ICaCE scores for concept gore is -0.0328004449451714%\nrelative ICaCE scores for concept misogynistic is 0.17255886253760835%\nrelative ICaCE scores for concept immigration is 0.00142610630195856%\nrelative ICaCE scores for concept extremism is -0.2809429414868636%\nrelative ICaCE scores for concept immoral is 0.2581252406554333%\nrelative ICaCE scores for concept white supremacy is 0.03565265754908852%\nimmoral anti muslim violence international relation misogynistic genocide politics white supremacy immigration \n\n48 {'text': 'we said we would never forget why are you voting them into our government?', 'img': 'img/74386.png', 'label': 1}\ntensor([0.7734, 0.2266], device='cuda:0', grad_fn=<SelectBackward0>)\npredicted class non offensive\n[0.00176328 0.00176358 0.00176072 0.00176316 0.00176698 0.00176239\n 0.00176471 0.00176406 0.00176191 0.00176257 0.00176316 0.00176817\n 0.00176454 0.00176203 0.00175959 0.00176585 0.00176454 0.00176501]\nrelative ICaCE scores for concept holocaust is -0.022530387860631117%\nrelative ICaCE scores for concept nazism is -0.005632596965160853%\nrelative ICaCE scores for concept genocide is -0.1678513895616754%\nrelative ICaCE scores for concept funny is -0.02928950421881922%\nrelative ICaCE scores for concept anti muslim is 0.18700221924320015%\nrelative ICaCE scores for concept terrorism is -0.07322376054704191%\nrelative ICaCE scores for concept violence is 0.05857900843762615%\nrelative ICaCE scores for concept politics is 0.02140386846759157%\nrelative ICaCE scores for concept racism is -0.10026022597979434%\nrelative ICaCE scores for concept international relation is -0.06308508600975975%\nrelative ICaCE scores for concept adult is -0.02928950421881922%\nrelative ICaCE scores for concept gore is 0.25459338282508126%\nrelative ICaCE scores for concept misogynistic is 0.048440333900343996%\nrelative ICaCE scores for concept immigration is -0.09350110962160622%\nrelative ICaCE scores for concept extremism is -0.2320629949644624%\nrelative ICaCE scores for concept immoral is 0.12279061384041316%\nrelative ICaCE scores for concept white supremacy is 0.048440333900343996%\ngore anti muslim immoral violence misogynistic white supremacy politics \n\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from captum.attr import IntegratedGradients\n",
        "\n",
        "# # input1 = torch.tensor([[1.0, 3.0], [3.0, 5.0]], requires_grad=True)\n",
        "# # input2 = torch.tensor([[1.0, 4.0], [0.0, 2.0]], requires_grad=True)\n",
        "# # # Initializing our toy model\n",
        "# # model = ToyModel_With_Additional_Forward_Args()\n",
        "# # # Applying integrated gradients on the input\n",
        "# ig = IntegratedGradients(vb)\n",
        "# (input1_attr, input2_attr), delta = ig.attribute((input1, input2), n_steps=100,\n",
        "#                                     additional_forward_args=1, return_convergence_delta=True)\n",
        "# output\n",
        "# .........\n",
        "# input1_attr: tensor([[0.0000, 0.0000],\n",
        "#                      [0.0000, 3.3428]], grad_fn=<MulBackward0>)\n",
        "# input2_attr:  tensor([[ 0.0000,  0.0000],\n",
        "#                       [0.0000, -1.3371]], grad_fn=<MulBackward0>)\n",
        "# approximation_error (aka delta): 0.005693793296813965"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:14.384776Z",
          "iopub.execute_input": "2024-09-21T20:32:14.385576Z",
          "iopub.status.idle": "2024-09-21T20:32:14.393377Z",
          "shell.execute_reply.started": "2024-09-21T20:32:14.385518Z",
          "shell.execute_reply": "2024-09-21T20:32:14.392344Z"
        },
        "trusted": true,
        "id": "l7JsdJuIZeXv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "concept_classes"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:14.395660Z",
          "iopub.execute_input": "2024-09-21T20:32:14.397312Z",
          "iopub.status.idle": "2024-09-21T20:32:14.410095Z",
          "shell.execute_reply.started": "2024-09-21T20:32:14.397268Z",
          "shell.execute_reply": "2024-09-21T20:32:14.408873Z"
        },
        "trusted": true,
        "id": "qXs5rkolZeXv",
        "outputId": "a32bda6e-bd33-467d-b3b0-94bb9c3ff13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 65,
          "output_type": "execute_result",
          "data": {
            "text/plain": "['holocaust',\n 'nazism',\n 'genocide',\n 'funny',\n 'anti muslim',\n 'terrorism',\n 'violence',\n 'politics',\n 'racism',\n 'international relation',\n 'adult',\n 'gore',\n 'misogynistic',\n 'immigration',\n 'extremism',\n 'immoral',\n 'white supremacy',\n 'indecency']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vb"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:14.412235Z",
          "iopub.execute_input": "2024-09-21T20:32:14.413236Z",
          "iopub.status.idle": "2024-09-21T20:32:14.425664Z",
          "shell.execute_reply.started": "2024-09-21T20:32:14.413190Z",
          "shell.execute_reply": "2024-09-21T20:32:14.424593Z"
        },
        "trusted": true,
        "id": "fGzRAnUQZeXv",
        "outputId": "f02f61b8-e1c4-4bc6-fc17-94eefdaf95af"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 66,
          "output_type": "execute_result",
          "data": {
            "text/plain": "VB(\n  (vb): VisualBertModel(\n    (embeddings): VisualBertEmbeddings(\n      (word_embeddings): Embedding(30522, 768, padding_idx=1)\n      (position_embeddings): Embedding(512, 768)\n      (token_type_embeddings): Embedding(2, 768)\n      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n      (dropout): Dropout(p=0.1, inplace=False)\n      (visual_token_type_embeddings): Embedding(2, 768)\n      (visual_position_embeddings): Embedding(512, 768)\n      (visual_projection): Linear(in_features=2048, out_features=768, bias=True)\n    )\n    (encoder): VisualBertEncoder(\n      (layer): ModuleList(\n        (0-11): 12 x VisualBertLayer(\n          (attention): VisualBertAttention(\n            (self): VisualBertSelfAttention(\n              (query): Linear(in_features=768, out_features=768, bias=True)\n              (key): Linear(in_features=768, out_features=768, bias=True)\n              (value): Linear(in_features=768, out_features=768, bias=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n            (output): VisualBertSelfOutput(\n              (dense): Linear(in_features=768, out_features=768, bias=True)\n              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n              (dropout): Dropout(p=0.1, inplace=False)\n            )\n          )\n          (intermediate): VisualBertIntermediate(\n            (dense): Linear(in_features=768, out_features=3072, bias=True)\n            (intermediate_act_fn): GELUActivation()\n          )\n          (output): VisualBertOutput(\n            (dense): Linear(in_features=3072, out_features=768, bias=True)\n            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n      )\n    )\n    (pooler): VisualBertPooler(\n      (dense): Linear(in_features=768, out_features=768, bias=True)\n      (activation): Tanh()\n    )\n  )\n  (linear_relu_stack): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_latent): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (linear_relu_stack_hidden): Sequential(\n    (0): Dropout(p=0.1, inplace=False)\n    (1): Linear(in_features=768, out_features=512, bias=True)\n    (2): ReLU()\n    (3): Linear(in_features=512, out_features=128, bias=True)\n    (4): ReLU()\n    (5): Linear(in_features=128, out_features=2, bias=True)\n  )\n  (project_latent): Linear(in_features=768, out_features=2048, bias=True)\n  (proj_conc): Linear(in_features=768, out_features=28, bias=True)\n  (proj_embed): Linear(in_features=768, out_features=28, bias=True)\n  (grad_rev1): RevGrad()\n  (grad_rev2): RevGrad()\n)"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "torch.manual_seed(SEED)\n",
        "random.seed(SEED)\n",
        "baselines = (torch.randn(20,18,768).to('cuda'), torch.randn(20,64,768).to('cuda'), torch.randn(20,36,2048).to('cuda'))\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:14.427690Z",
          "iopub.execute_input": "2024-09-21T20:32:14.428692Z",
          "iopub.status.idle": "2024-09-21T20:32:14.471916Z",
          "shell.execute_reply.started": "2024-09-21T20:32:14.428486Z",
          "shell.execute_reply": "2024-09-21T20:32:14.470952Z"
        },
        "trusted": true,
        "id": "oPgNTpMLZeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "from captum.attr import IntegratedGradients,Saliency,DeepLift,DeepLiftShap, GradientShap, InputXGradient, KernelShap, FeatureAblation\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:19.880789Z",
          "iopub.execute_input": "2024-09-21T20:32:19.881160Z",
          "iopub.status.idle": "2024-09-21T20:32:19.960591Z",
          "shell.execute_reply.started": "2024-09-21T20:32:19.881131Z",
          "shell.execute_reply": "2024-09-21T20:32:19.959435Z"
        },
        "trusted": true,
        "id": "vq0rLakuZeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# torch.manual_seed(42)\n",
        "# print(torch.randn(2,3))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:22.912776Z",
          "iopub.execute_input": "2024-09-21T20:32:22.913407Z",
          "iopub.status.idle": "2024-09-21T20:32:22.917240Z",
          "shell.execute_reply.started": "2024-09-21T20:32:22.913375Z",
          "shell.execute_reply": "2024-09-21T20:32:22.916098Z"
        },
        "trusted": true,
        "id": "BvauKqDxZeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "#vb_wrapper = VB_wrapper(vb)\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:23.321103Z",
          "iopub.execute_input": "2024-09-21T20:32:23.321456Z",
          "iopub.status.idle": "2024-09-21T20:32:23.325336Z",
          "shell.execute_reply.started": "2024-09-21T20:32:23.321430Z",
          "shell.execute_reply": "2024-09-21T20:32:23.324467Z"
        },
        "trusted": true,
        "id": "_52UiT26ZeXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "!pip install shutup"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:23.755008Z",
          "iopub.execute_input": "2024-09-21T20:32:23.755946Z",
          "iopub.status.idle": "2024-09-21T20:32:36.215506Z",
          "shell.execute_reply.started": "2024-09-21T20:32:23.755912Z",
          "shell.execute_reply": "2024-09-21T20:32:36.214313Z"
        },
        "trusted": true,
        "id": "R-a1DdIsZeXx",
        "outputId": "d05c1c17-0cee-4306-d401-b2885a660b13"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "Collecting shutup\n  Downloading shutup-0.2.0-py3-none-any.whl.metadata (530 bytes)\nDownloading shutup-0.2.0-py3-none-any.whl (1.5 kB)\nInstalling collected packages: shutup\nSuccessfully installed shutup-0.2.0\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(gc)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:36.217528Z",
          "iopub.execute_input": "2024-09-21T20:32:36.217856Z",
          "iopub.status.idle": "2024-09-21T20:32:36.224576Z",
          "shell.execute_reply.started": "2024-09-21T20:32:36.217827Z",
          "shell.execute_reply": "2024-09-21T20:32:36.223704Z"
        },
        "trusted": true,
        "id": "w_r9x5DKZeXx",
        "outputId": "ea20a5f3-c0bb-4847-82fe-a4a3ffa58252"
      },
      "execution_count": null,
      "outputs": [
        {
          "execution_count": 72,
          "output_type": "execute_result",
          "data": {
            "text/plain": "208"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def call_sim():\n",
        "\n",
        "    import math\n",
        "    # Quantitative case study (1) Faithfulness on concepts\n",
        "    # Quantitative case study (2) Are they explainable?\n",
        "    test_dataloader=DataLoader(t_p, shuffle=True, batch_size=1)\n",
        "\n",
        "    pred_r1, pred_r2 = [],[]\n",
        "    pred_both = []\n",
        "    act = []\n",
        "\n",
        "    multimodal_repr = []\n",
        "    concept_repr = []\n",
        "\n",
        "    concept_repr1 = []\n",
        "    concept_repr2 = []\n",
        "    y_p = []\n",
        "\n",
        "    cr, rr = [],[]\n",
        "    cr1,rr1 = [],[]\n",
        "\n",
        "\n",
        "    ours_icace = []\n",
        "    ia_icace = []\n",
        "\n",
        "    concept_cat = {}\n",
        "    for i,c in enumerate(concept_classes):\n",
        "        concept_cat[c] = all_concepts[i]\n",
        "\n",
        "    for ii, batch in tqdm(enumerate(eval_dataloader)):\n",
        "\n",
        "        #if batch[1].detach().cpu().numpy()[0] == 1:\n",
        "\n",
        "        ll = batch[1].detach().cpu().numpy()[0]\n",
        "        y_p.append(ll)\n",
        "\n",
        "        #print('*'*10)\n",
        "\n",
        "        input_ids = batch[0]['input_ids'].to('cuda')\n",
        "        #print(tokenizer.batch_decode(batch[0]['input_ids'], skip_special_tokens=True))\n",
        "        token_type_ids = batch[0]['token_type_ids'].to('cuda')\n",
        "        attention_mask = batch[0]['attention_mask'].to('cuda')\n",
        "        visual_embeds = batch[0]['visual_embeds'].to('cuda')\n",
        "        visual_token_type_ids = batch[0]['visual_token_type_ids'].to('cuda')\n",
        "        visual_attention_mask = batch[0]['visual_attention_mask'].to('cuda')\n",
        "\n",
        "        inputs_embeds = vb_wrapper.vb.vb.embeddings.word_embeddings(input_ids)\n",
        "\n",
        "        #     (input1_attr, input2_attr), delta = ig.attribute(inputs = (all_concepts.to('cuda'), inputs_embeds), additional_forward_args = (attention_mask,\n",
        "        #         token_type_ids,\n",
        "        #         None,\n",
        "        #         None,\n",
        "        #         None,\n",
        "        #         visual_embeds,\n",
        "        #         visual_attention_mask,\n",
        "        #         visual_token_type_ids), return_convergence_delta=True)\n",
        "\n",
        "        #print(visual_embeds)\n",
        "\n",
        "        #     (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_concepts.unsqueeze(0).to('cuda'), inputs_embeds, visual_embeds), additional_forward_args = (attention_mask,\n",
        "        #         token_type_ids,\n",
        "        #         None,\n",
        "        #         None,\n",
        "        #         None,\n",
        "        #         visual_attention_mask,\n",
        "        #         visual_token_type_ids))\n",
        "        #vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds_latent, visual_attention_mask=visual_attention_mask_latent, visual_token_type_ids=visual_token_type_ids_latent)\n",
        "\n",
        "        if type(ig) in [captum.attr._core.kernel_shap.KernelShap, captum.attr._core.input_x_gradient.InputXGradient, captum.attr._core.deep_lift.DeepLift, captum.attr._core.saliency.Saliency, captum.attr._core.integrated_gradients.IntegratedGradients, captum.attr._core.feature_ablation.FeatureAblation]:\n",
        "                baseline = None\n",
        "                #print('none')\n",
        "        else:\n",
        "            baseline = baselines\n",
        "            #print('baseline')\n",
        "\n",
        "        all_conc = all_concepts.to('cuda')\n",
        "        if type(ig) in [captum.attr._core.input_x_gradient.InputXGradient,captum.attr._core.saliency.Saliency]:\n",
        "            #print('ip_grad')\n",
        "            (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_conc.unsqueeze(0), inputs_embeds, visual_embeds),\n",
        "\n",
        "                                                                additional_forward_args = (attention_mask,\n",
        "            token_type_ids,\n",
        "            None,\n",
        "            None,\n",
        "            None,\n",
        "            visual_attention_mask,\n",
        "            visual_token_type_ids))\n",
        "\n",
        "        else:\n",
        "            #print('others')\n",
        "\n",
        "            (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_conc.unsqueeze(0), inputs_embeds, visual_embeds),\n",
        "                                                                  baselines = baseline,\n",
        "                                                                    additional_forward_args = (attention_mask,\n",
        "                token_type_ids,\n",
        "                None,\n",
        "                None,\n",
        "                None,\n",
        "                visual_attention_mask,\n",
        "                visual_token_type_ids))\n",
        "\n",
        "\n",
        "        #print(input1_attr, input2_attr)\n",
        "        #print(input1_attr.shape, input2_attr.shape)\n",
        "        k1=input1_attr.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "        conc_scr = []\n",
        "        attribution_score = {}\n",
        "        for i in range(18):\n",
        "            cc = concept_classes[i]\n",
        "            #print('relative attribution scores for concept {} is {}'.format(cc,k[i]))\n",
        "            conc_scr.append((cc,k1[i]))\n",
        "            attribution_score[cc] = k1[i]\n",
        "            #conc_scr[cc] = k1[i]\n",
        "        conc_scr.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "        d = {}\n",
        "\n",
        "        for cnt,i in enumerate(conc_scr):\n",
        "            d[i[0]] = cnt\n",
        "\n",
        "        #print(d)\n",
        "\n",
        "\n",
        "        orig,pooled_op = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts)\n",
        "        orig = orig[0]\n",
        "        pooled_op = pooled_op.detach().cpu()\n",
        "        multimodal_repr.append(pooled_op)\n",
        "        #print('predicted class {}'.format(class_map[np.argmax(orig.detach().cpu().numpy())]))\n",
        "        #print('actual class {}'.format(ll))\n",
        "        #print(0/0)\n",
        "        #orig = orig[0]\n",
        "        k = []\n",
        "        pred_class = np.argmax(orig.detach().cpu().numpy())\n",
        "        causal_score = {}\n",
        "        #print(pred_class)\n",
        "        for i in range(18):\n",
        "            #print('Removing concept: {}'.format(concept_classes[i]))\n",
        "            cc = concept_classes[i]\n",
        "            after_intervention,_ = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts,concept_no=i)\n",
        "            after_intervention = after_intervention[0][pred_class]\n",
        "            #print('hello')\n",
        "            #print(orig[pred_class], after_intervention)\n",
        "            #print(0/0)\n",
        "            k.append((cc,abs(after_intervention-orig[pred_class]).item()))\n",
        "            causal_score[cc] = abs(after_intervention-orig[pred_class]).item()\n",
        "            #print('model prediction after removal {}'.format(model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,concept_no=i)))\n",
        "        #k = np.asarray(k)\n",
        "        #k = np.asarray(k)\n",
        "        #k = list(map(lambda x: ((x-np.mean(k))/np.mean(k))*100, k))\n",
        "        k.sort(key=lambda tup: tup[1], reverse=True)\n",
        "        #print(k)\n",
        "\n",
        "        #print(list(map(lambda x: x[0], list(k))))\n",
        "\n",
        "        gamma = 0.9\n",
        "        temp = []\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "            temp.append((gamma**cnt) * concept_cat[i])\n",
        "            #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "            #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "        temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "        #print(temp)\n",
        "        #print(temp.shape)\n",
        "\n",
        "        concept_repr.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "        temp = []\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(conc_scr)))):\n",
        "            temp.append((gamma**cnt) * concept_cat[i])\n",
        "            #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "            #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "        temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "        #print(temp)\n",
        "        #print(temp.shape)\n",
        "\n",
        "        concept_repr1.append(temp)\n",
        "\n",
        "\n",
        "        #print(list(map(lambda x: x[0], list(conc_scr))))\n",
        "        #print(0/0)\n",
        "\n",
        "        #considering the k to be the causally sorted rank, we estimate ranks of\n",
        "\n",
        "        ip_attrib_causal = []\n",
        "\n",
        "\n",
        "\n",
        "        for i in range(18):\n",
        "            cc = concept_classes[i]\n",
        "            ip_attrib_causal.append((cc,((2*attribution_score[cc]*causal_score[cc]) / (attribution_score[cc]+causal_score[cc]))))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        ip_attrib_causal.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "        ra_icace_ours = []\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "            ra_icace_ours.append((gamma**cnt) * causal_score[i])\n",
        "            #ra_icace_ours.append((math.e**(-cnt)) * causal_score[i])\n",
        "            #ra_icace_ours.append((1.1**(-cnt)) * causal_score[i])\n",
        "\n",
        "        ra_icace_ia = []\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(conc_scr)))):\n",
        "            ra_icace_ia.append((gamma**cnt) * causal_score[i])\n",
        "            #ra_icace_ia.append((math.e**(-cnt)) * causal_score[i])\n",
        "            #ra_icace_ia.append((1.1**(-cnt)) * causal_score[i])\n",
        "\n",
        "\n",
        "\n",
        "        ours_icace.append(np.mean(ra_icace_ours))\n",
        "        ia_icace.append(np.mean(ra_icace_ia))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        temp = []\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(ip_attrib_causal)))):\n",
        "            temp.append((gamma**cnt) * concept_cat[i])\n",
        "            #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "            #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "        temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "\n",
        "        concept_repr2.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "        d1 = {}\n",
        "\n",
        "        for cnt,i in enumerate(ip_attrib_causal):\n",
        "            d1[i[0]] = cnt\n",
        "\n",
        "        r1,r2,r3 = [],[],[]\n",
        "        for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "            r1.append(cnt)\n",
        "            r2.append(d[i])\n",
        "            r3.append(d1[i])\n",
        "\n",
        "        #print(r1,r2)\n",
        "        corr, _ = stats.kendalltau(r1, r2)\n",
        "        res,_ = stats.spearmanr(r1, r2)\n",
        "\n",
        "        corr1, _ = stats.kendalltau(r1, r3)\n",
        "        res1,_ = stats.spearmanr(r1, r3)\n",
        "\n",
        "        #print('kendall tau', corr)\n",
        "        cr.append(corr)\n",
        "        #print('spearmans rho', res)\n",
        "        rr.append(res)\n",
        "\n",
        "        cr1.append(corr1)\n",
        "        rr1.append(res1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    multimodal_repr = torch.stack(multimodal_repr).squeeze(1)\n",
        "\n",
        "    #causal\n",
        "    concept_repr = torch.stack(concept_repr).squeeze(1)\n",
        "\n",
        "\n",
        "    #attribution\n",
        "    concept_repr1 = torch.stack(concept_repr1).squeeze(1)\n",
        "\n",
        "    #HM\n",
        "    concept_repr2 = torch.stack(concept_repr2).squeeze(1)\n",
        "\n",
        "\n",
        "    return np.mean(cr), np.mean(rr), multimodal_repr, concept_repr, concept_repr1, y_p\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:36.226034Z",
          "iopub.execute_input": "2024-09-21T20:32:36.226405Z",
          "iopub.status.idle": "2024-09-21T20:32:36.268629Z",
          "shell.execute_reply.started": "2024-09-21T20:32:36.226373Z",
          "shell.execute_reply": "2024-09-21T20:32:36.267870Z"
        },
        "trusted": true,
        "id": "ORerPym9ZeXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /kaggle/working"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:36.270567Z",
          "iopub.execute_input": "2024-09-21T20:32:36.270835Z",
          "iopub.status.idle": "2024-09-21T20:32:37.360618Z",
          "shell.execute_reply.started": "2024-09-21T20:32:36.270813Z",
          "shell.execute_reply": "2024-09-21T20:32:37.359461Z"
        },
        "trusted": true,
        "id": "TETFsy-wZeXy",
        "outputId": "6561442d-03e1-419d-f52f-f11bb7e66bbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "25461.png\t   cr1.pt\t\t\t  mean_comparison_plot.png\n28076.png\t   cr2.pt\t\t\t  mr.pt\n94162.png\t   final_model_concept.pt\t  rr.npy\n96704.png\t   final_model_concept_inlp.pt\t  rr1.npy\ncausal_vb.pt\t   final_model_wo_adversarial.pt  transformers\ncausal_vb_inlp.pt  foo1.png\t\t\t  vs_tensors.pt\ncr.npy\t\t   full_annotation.pkl\t\t  y_p.pt\ncr.pt\t\t   image1.jpg\ncr1.npy\t\t   image2.jpg\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(DECONFOUND, DYN_ROUTE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:37.362082Z",
          "iopub.execute_input": "2024-09-21T20:32:37.362439Z",
          "iopub.status.idle": "2024-09-21T20:32:37.367827Z",
          "shell.execute_reply.started": "2024-09-21T20:32:37.362409Z",
          "shell.execute_reply": "2024-09-21T20:32:37.366843Z"
        },
        "trusted": true,
        "id": "ZMsMFfiKZeXy",
        "outputId": "27745964-285d-4f20-c68e-ab7001a35170"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "text": "True True\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#clf = svm.SVC(kernel='poly', C=2, random_state=42)\n",
        "\n",
        "def get_sim(multimodal_repr, concept_repr1, y_p):\n",
        "\n",
        "    X = np.concatenate([multimodal_repr.numpy(),concept_repr1.numpy()],axis=-1) # inp w/ clip representation w/ exp -> w/ both\n",
        "    #X = (multimodal_repr.numpy()*concept_repr.numpy())\n",
        "    X_ = multimodal_repr.numpy() # inp w/ clip representation w/o exp -> w/ only input\n",
        "    X__ = concept_repr1.numpy() # inp w/o clip representation w/ exp -> w/ only exp\n",
        "\n",
        "    print(X.shape)\n",
        "    print(X_.shape)\n",
        "    print(X__.shape)\n",
        "    print(y_p)\n",
        "    #print(0/0)\n",
        "\n",
        "\n",
        "\n",
        "    kf = KFold(n_splits=5)\n",
        "    y = np.array(y_p)\n",
        "    vals = []\n",
        "    vals_lus = []\n",
        "    k1,k2,k3 = [],[],[]\n",
        "    C,S = [],[]\n",
        "    for train, test in kf.split(X):\n",
        "\n",
        "        X_train, X_test, y_train, y_test = X[train], X[test], y[train], y[test]\n",
        "        X_train_, X_test_, y_train, y_test = X_[train], X_[test], y[train], y[test]\n",
        "        X_train__, X_test__, y_train, y_test = X__[train], X__[test], y[train], y[test]\n",
        "\n",
        "\n",
        "        clf1 = make_pipeline(StandardScaler(),svm.SVC(probability=True, kernel='rbf', C=2, random_state=42))\n",
        "        clf1.fit(X_train, y_train)\n",
        "        y_pred = clf1.predict(X_test)\n",
        "\n",
        "        clf2 = make_pipeline(StandardScaler(),svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n",
        "        clf2.fit(X_train_, y_train)\n",
        "        y_pred_ = clf2.predict(X_test_)\n",
        "\n",
        "        clf3 = make_pipeline(StandardScaler(), svm.SVC(probability=True,kernel='rbf', C=2, random_state=42))\n",
        "        clf3.fit(X_train__, y_train)\n",
        "        y_pred__ = clf3.predict(X_test__)\n",
        "\n",
        "\n",
        "        y_pred_proba_w_both = clf1.predict_proba(X_test)\n",
        "        y_pred_proba_w_inp = clf2.predict_proba(X_test_)\n",
        "        y_pred_proba_w_exp = clf3.predict_proba(X_test__)\n",
        "\n",
        "\n",
        "\n",
        "        comprehensiveness, sufficiency = 0,0\n",
        "\n",
        "        counter = 0\n",
        "        for pred_proba_w_both, pred_proba_w_inp, pred_proba_w_exp, pred_class in zip(y_pred_proba_w_both,y_pred_proba_w_inp,y_pred_proba_w_exp,y_pred):\n",
        "            comprehensiveness += (pred_proba_w_both[pred_class] - pred_proba_w_inp[pred_class])\n",
        "            sufficiency += (pred_proba_w_both[pred_class] - pred_proba_w_exp[pred_class])\n",
        "            counter+=1\n",
        "\n",
        "\n",
        "        comprehensiveness = comprehensiveness / counter\n",
        "        sufficiency = sufficiency / counter\n",
        "\n",
        "        C.append(comprehensiveness)\n",
        "        S.append(sufficiency)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "        l, nl = 0,0\n",
        "        us = 0\n",
        "        for i ,j in zip(y_pred__,y_test):\n",
        "            if i==j:\n",
        "                l+=1\n",
        "            else:\n",
        "                nl+=1\n",
        "        a,b=0,0\n",
        "        for i,j,k,x in zip(y_pred,y_pred_,y_test,y_pred__):\n",
        "            us+=int(i==k) - int(j==k)\n",
        "            if k==x:\n",
        "                a += int(i==k) - int(j==k)\n",
        "            elif k!=x:\n",
        "                b += int(i==k) - int(j==k)\n",
        "\n",
        "        #print('LAS ',.5*(a/l)+.5*(b/nl))\n",
        "        #print('Leakage Unadjusted Simulatability (LUS)', (us/(l+nl)))\n",
        "        vals_lus.append(us/(l+nl))\n",
        "        #print('Comprehensiveness ', comprehensiveness)\n",
        "        #print('Sufficiency ', sufficiency)\n",
        "        #print('f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(f1_score(y_test, y_pred, average='macro')))\n",
        "        #print('f1 between prediction of proposed model and SVM w/ only inp {}'.format(f1_score(y_test, y_pred_, average='macro')))\n",
        "        #print('f1 between prediction of proposed model and SVM w/ only exp {}'.format(f1_score(y_test, y_pred__, average='macro')))\n",
        "        vals.append(.5*(a/l)+.5*(b/nl))\n",
        "        k1.append(f1_score(y_test, y_pred, average='macro'))\n",
        "        k2.append(f1_score(y_test, y_pred_, average='macro'))\n",
        "        k3.append(f1_score(y_test, y_pred__, average='macro'))\n",
        "\n",
        "\n",
        "    #print('Intra mean ', np.mean(ID), 'Intra std ', np.std(ID))\n",
        "    #print('Inter mean ', np.mean(ID1), 'Inter std ', np.std(ID1))\n",
        "    print('LAS mean ', np.mean(vals), 'LAS std ', np.std(vals))\n",
        "    print('LUS mean ', np.mean(vals_lus), 'LUS std ', np.std(vals_lus))\n",
        "    print('Comprehensiveness mean ', np.mean(C), 'Comprehensiveness std ', np.std(C))\n",
        "    print('Sufficiency mean ', np.mean(S), 'Sufficiency std ', np.std(S))\n",
        "    print('Avg. f1 between prediction of proposed model and SVM w/ both inp and exp {}'.format(np.mean(k1)))\n",
        "    print('Avg. f1 between prediction of proposed model and SVM w/ only inp {}'.format(np.mean(k2)))\n",
        "    print('Avg. f1 between prediction of proposed model and SVM w/ only exp {}'.format(np.mean(k3)))\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:37.369064Z",
          "iopub.execute_input": "2024-09-21T20:32:37.369451Z",
          "iopub.status.idle": "2024-09-21T20:32:37.391034Z",
          "shell.execute_reply.started": "2024-09-21T20:32:37.369427Z",
          "shell.execute_reply": "2024-09-21T20:32:37.390165Z"
        },
        "trusted": true,
        "id": "X-6V7RmrZeXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wIDQFT6_ZeXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#R\n",
        "cd = {i:[] for i in concept_classes}\n",
        "import shutup; shutup.please()\n",
        "def call():\n",
        "    import math\n",
        "    # Quantitative case study (1) Faithfulness on concepts\n",
        "    # Quantitative case study (2) Are they explainable?\n",
        "    test_dataloader=DataLoader(t_p, shuffle=True, batch_size=1)\n",
        "\n",
        "    pred_r1, pred_r2 = [],[]\n",
        "    pred_both = []\n",
        "    act = []\n",
        "\n",
        "    multimodal_repr = []\n",
        "    concept_repr = []\n",
        "\n",
        "    concept_repr1 = []\n",
        "    concept_repr2 = []\n",
        "    y_p = []\n",
        "\n",
        "    cr, rr = [],[]\n",
        "    cr1,rr1 = [],[]\n",
        "\n",
        "\n",
        "    ours_icace = []\n",
        "    ia_icace = []\n",
        "\n",
        "    counter = 0\n",
        "\n",
        "\n",
        "    c_p=0\n",
        "    c_r=0\n",
        "\n",
        "    a_p=0\n",
        "    a_r=0\n",
        "\n",
        "    average_precision_causal = 0\n",
        "    average_precision_attrib = 0\n",
        "\n",
        "    concept_cat = {}\n",
        "    for i,c in enumerate(concept_classes):\n",
        "        concept_cat[c] = all_concepts[i]\n",
        "\n",
        "    for ii, batch in tqdm(enumerate(eval_dataloader)):\n",
        "\n",
        "        if ii==0:\n",
        "            print(ig)\n",
        "\n",
        "        #if batch[1].detach().cpu().numpy()[0] == 1:\n",
        "\n",
        "        ll = batch[1].detach().cpu().numpy()[0]\n",
        "        if ll==1:\n",
        "\n",
        "            #ll = batch[1].detach().cpu().numpy()[0]\n",
        "            #print(ll, ii)\n",
        "            y_p.append(ll)\n",
        "\n",
        "            #print('*'*10)\n",
        "\n",
        "            input_ids = batch[0]['input_ids'].to('cuda')\n",
        "            #print(tokenizer.batch_decode(batch[0]['input_ids'], skip_special_tokens=True))\n",
        "            token_type_ids = batch[0]['token_type_ids'].to('cuda')\n",
        "            attention_mask = batch[0]['attention_mask'].to('cuda')\n",
        "            visual_embeds = batch[0]['visual_embeds'].to('cuda')\n",
        "            visual_token_type_ids = batch[0]['visual_token_type_ids'].to('cuda')\n",
        "            visual_attention_mask = batch[0]['visual_attention_mask'].to('cuda')\n",
        "\n",
        "            inputs_embeds = vb_wrapper.vb.vb.embeddings.word_embeddings(input_ids)\n",
        "\n",
        "            # print(inputs_embeds)\n",
        "            #     (input1_attr, input2_attr), delta = ig.attribute(inputs = (all_concepts.to('cuda'), inputs_embeds), additional_forward_args = (attention_mask,\n",
        "            #         token_type_ids,\n",
        "            #         None,\n",
        "            #         None,\n",
        "            #         None,\n",
        "            #         visual_embeds,\n",
        "            #         visual_attention_mask,\n",
        "            #         visual_token_type_ids), return_convergence_delta=True)\n",
        "\n",
        "            #print(visual_embeds)\n",
        "\n",
        "            #     (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_concepts.unsqueeze(0).to('cuda'), inputs_embeds, visual_embeds), additional_forward_args = (attention_mask,\n",
        "            #         token_type_ids,\n",
        "            #         None,\n",
        "            #         None,\n",
        "            #         None,\n",
        "            #         visual_attention_mask,\n",
        "            #         visual_token_type_ids))\n",
        "            #vb(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask, visual_embeds=visual_embeds_latent, visual_attention_mask=visual_attention_mask_latent, visual_token_type_ids=visual_token_type_ids_latent)\n",
        "\n",
        "            if type(ig) in [captum.attr._core.kernel_shap.KernelShap, captum.attr._core.input_x_gradient.InputXGradient, captum.attr._core.deep_lift.DeepLift, captum.attr._core.saliency.Saliency, captum.attr._core.integrated_gradients.IntegratedGradients, captum.attr._core.feature_ablation.FeatureAblation]:\n",
        "                    baseline = None\n",
        "                    #print('none')\n",
        "            else:\n",
        "                baseline = baselines\n",
        "                #print('baseline')\n",
        "\n",
        "            if DECONFOUND:\n",
        "                all_conc = get_inlp(all_concepts).to('cuda')\n",
        "            else:\n",
        "                all_conc = all_concepts.to('cuda')\n",
        "\n",
        "            #print(all_conc)\n",
        "            #print(all_concepts)\n",
        "\n",
        "            #print(0/0)\n",
        "\n",
        "            #all_conc = all_concepts.to('cuda')\n",
        "\n",
        "            if type(ig) in [captum.attr._core.input_x_gradient.InputXGradient,captum.attr._core.saliency.Saliency]:\n",
        "                #print('ip_grad')\n",
        "                (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_conc.unsqueeze(0).to('cuda'), inputs_embeds, visual_embeds),\n",
        "\n",
        "                                                                    additional_forward_args = (attention_mask,\n",
        "                token_type_ids,\n",
        "                None,\n",
        "                None,\n",
        "                None,\n",
        "                visual_attention_mask,\n",
        "                visual_token_type_ids))\n",
        "\n",
        "            else:\n",
        "                #print('others')\n",
        "\n",
        "                (input1_attr, input2_attr, input3_attr) = ig.attribute(inputs = (all_conc.unsqueeze(0).to('cuda'), inputs_embeds, visual_embeds),\n",
        "                                                                      baselines = baseline,\n",
        "                                                                        additional_forward_args = (attention_mask,\n",
        "                    token_type_ids,\n",
        "                    None,\n",
        "                    None,\n",
        "                    None,\n",
        "                    visual_attention_mask,\n",
        "                    visual_token_type_ids))\n",
        "\n",
        "\n",
        "            #print(input1_attr, input2_attr)\n",
        "            #print(input1_attr.shape, input2_attr.shape)\n",
        "            k1=input1_attr.sum(dim=-1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "            conc_scr = []\n",
        "            attribution_score = {}\n",
        "            for i in range(18):\n",
        "                cc = concept_classes[i]\n",
        "                #print('relative attribution scores for concept {} is {}'.format(cc,k[i]))\n",
        "                conc_scr.append((cc,k1[i]))\n",
        "                attribution_score[cc] = k1[i]\n",
        "                #conc_scr[cc] = k1[i]\n",
        "            conc_scr.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "            d = {}\n",
        "\n",
        "            for cnt,i in enumerate(conc_scr):\n",
        "                d[i[0]] = cnt\n",
        "\n",
        "            #print(d)\n",
        "\n",
        "\n",
        "            orig,pooled_op = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts)\n",
        "            orig = orig[0]\n",
        "            pooled_op = pooled_op.detach().cpu()\n",
        "            multimodal_repr.append(pooled_op)\n",
        "            #print('predicted class {}'.format(class_map[np.argmax(orig.detach().cpu().numpy())]))\n",
        "            #print('actual class {}'.format(ll))\n",
        "            #print(0/0)\n",
        "            #orig = orig[0]\n",
        "            k = []\n",
        "            pred_class = np.argmax(orig.detach().cpu().numpy())\n",
        "            causal_score = {}\n",
        "            #print(pred_class)\n",
        "            for i in range(18):\n",
        "                #print('Removing concept: {}'.format(concept_classes[i]))\n",
        "                cc = concept_classes[i]\n",
        "                after_intervention,_ = model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,all_concepts,concept_no=i)\n",
        "                after_intervention = after_intervention[0][pred_class]\n",
        "                #print('hello')\n",
        "                #print(orig[pred_class], after_intervention)\n",
        "                #print(0/0)\n",
        "                k.append((cc,abs(after_intervention-orig[pred_class]).item()))\n",
        "                causal_score[cc] = abs(after_intervention-orig[pred_class]).item()\n",
        "                #print('model prediction after removal {}'.format(model_pred(input_ids,attention_mask,token_type_ids,visual_embeds,visual_attention_mask,visual_token_type_ids,concept_no=i)))\n",
        "            #k = np.asarray(k)\n",
        "            #k = np.asarray(k)\n",
        "            #k = list(map(lambda x: ((x-np.mean(k))/np.mean(k))*100, k))\n",
        "            k.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "            #print(k)\n",
        "\n",
        "            #random.seed(counter)\n",
        "            #random.shuffle(k)\n",
        "\n",
        "            #print(k)\n",
        "\n",
        "            #print(0/0)\n",
        "\n",
        "\n",
        "            for i in k:\n",
        "                cd[i[0]].append(i[1])\n",
        "\n",
        "\n",
        "\n",
        "            #print(list(map(lambda x: x[0], list(k))))\n",
        "\n",
        "            gamma = 0.9\n",
        "            temp = []\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "                temp.append((gamma**cnt) * concept_cat[i])\n",
        "                #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "                #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "            temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "            #print(temp)\n",
        "            #print(temp.shape)\n",
        "\n",
        "            concept_repr.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "            temp = []\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(conc_scr)))):\n",
        "                temp.append((gamma**cnt) * concept_cat[i])\n",
        "                #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "                #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "            temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "            #print(temp)\n",
        "            #print(temp.shape)\n",
        "\n",
        "            concept_repr1.append(temp)\n",
        "\n",
        "\n",
        "            #print(list(map(lambda x: x[0], list(conc_scr))))\n",
        "            #print(0/0)\n",
        "\n",
        "            #considering the k to be the causally sorted rank, we estimate ranks of\n",
        "\n",
        "            ip_attrib_causal = []\n",
        "\n",
        "\n",
        "\n",
        "            for i in range(18):\n",
        "                cc = concept_classes[i]\n",
        "                ip_attrib_causal.append((cc,((2*attribution_score[cc]*causal_score[cc]) / (attribution_score[cc]+causal_score[cc]))))\n",
        "\n",
        "\n",
        "\n",
        "            ip_attrib = []\n",
        "            for i in range(18):\n",
        "                cc = concept_classes[i]\n",
        "                ip_attrib.append((cc,attribution_score[cc]))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            ip_attrib_causal.sort(key=lambda tup: tup[1], reverse=True)\n",
        "            ip_attrib.sort(key=lambda tup: tup[1], reverse=True)\n",
        "\n",
        "\n",
        "\n",
        "            ra_icace_ours = []\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "                ra_icace_ours.append((gamma**cnt) * causal_score[i])\n",
        "                #ra_icace_ours.append((math.e**(-cnt)) * causal_score[i])\n",
        "                #ra_icace_ours.append((1.1**(-cnt)) * causal_score[i])\n",
        "\n",
        "            ra_icace_ia = []\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(conc_scr)))):\n",
        "                ra_icace_ia.append((gamma**cnt) * causal_score[i])\n",
        "                #ra_icace_ia.append((math.e**(-cnt)) * causal_score[i])\n",
        "                #ra_icace_ia.append((1.1**(-cnt)) * causal_score[i])\n",
        "\n",
        "\n",
        "\n",
        "            ours_icace.append(np.mean(ra_icace_ours))\n",
        "            ia_icace.append(np.mean(ra_icace_ia))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            temp = []\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(ip_attrib_causal)))):\n",
        "                temp.append((gamma**cnt) * concept_cat[i])\n",
        "                #temp.append((math.e**(-cnt)) * concept_cat[i])\n",
        "                #temp.append((1.1**(-cnt)) * concept_cat[i])\n",
        "\n",
        "            temp = torch.stack(temp).mean(dim=0).unsqueeze(dim=0)\n",
        "\n",
        "            concept_repr2.append(temp)\n",
        "\n",
        "\n",
        "\n",
        "            d1 = {}\n",
        "\n",
        "            for cnt,i in enumerate(ip_attrib_causal):\n",
        "                d1[i[0]] = cnt\n",
        "\n",
        "            r1,r2,r3 = [],[],[]\n",
        "            for cnt,i in enumerate(list(map(lambda x: x[0], list(k)))):\n",
        "                r1.append(cnt)\n",
        "                r2.append(d[i])\n",
        "                r3.append(d1[i])\n",
        "\n",
        "            #print(r1,r2)\n",
        "            corr, _ = stats.kendalltau(r1, r2)\n",
        "            res,_ = stats.spearmanr(r1, r2)\n",
        "\n",
        "            corr1, _ = stats.kendalltau(r1, r3)\n",
        "            res1,_ = stats.spearmanr(r1, r3)\n",
        "\n",
        "            #print('kendall tau', corr)\n",
        "            cr.append(corr)\n",
        "            #print('spearmans rho', res)\n",
        "            rr.append(res)\n",
        "\n",
        "            cr1.append(corr1)\n",
        "            rr1.append(res1)\n",
        "\n",
        "\n",
        "            rel_items = gc[counter]\n",
        "            causal = [i[0] for i in k]\n",
        "            #causal = random.sample(concept_classes,5)\n",
        "            attrib = [i[0] for i in ip_attrib]\n",
        "\n",
        "\n",
        "            #         mrr_causal = []\n",
        "            #         for i in range(len(causal)):\n",
        "            #             item = causal[i]\n",
        "            #             if item in rel_items:\n",
        "            #                 mrr_causal.append(1/(i+1))\n",
        "\n",
        "            #         mrr_attrib = []\n",
        "            #         for i in range(len(attrib)):\n",
        "            #             item = attrib[i]\n",
        "            #             if item in rel_items:\n",
        "            #                 mrr_attrib.append(1/(i+1))\n",
        "\n",
        "\n",
        "\n",
        "            #         mrr_causal = np.mean(np.asarray(mrr_causal))\n",
        "\n",
        "            #print('gc', rel_items)\n",
        "            #print('causal', causal)\n",
        "            #print('attrib', attrib)\n",
        "\n",
        "            K = 5\n",
        "\n",
        "            rel_rec_items_at_K = set(causal[:K]) & set(rel_items)\n",
        "            rec_items_at_K = causal[:K]\n",
        "            tot_rel_items = len(rel_items)\n",
        "\n",
        "            #print('Causal P@{} '.format(K), len(rel_rec_items_at_K) / len(rec_items_at_K) )\n",
        "            #print('Causal R@{} '.format(K), len(rel_rec_items_at_K) / tot_rel_items )\n",
        "\n",
        "            c_p+=len(rel_rec_items_at_K) / len(rec_items_at_K)\n",
        "            c_r+=len(rel_rec_items_at_K) / tot_rel_items\n",
        "\n",
        "\n",
        "            rel_rec_items_at_K = set(attrib[:K]) & set(rel_items)\n",
        "            rec_items_at_K = attrib[:K]\n",
        "            tot_rel_items = len(rel_items)\n",
        "\n",
        "            #print('Attrib P@{} '.format(K), len(rel_rec_items_at_K) / len(rec_items_at_K) )\n",
        "            #print('Attrib R@{} '.format(K), len(rel_rec_items_at_K) / tot_rel_items )\n",
        "\n",
        "            a_p+=len(rel_rec_items_at_K) / len(rec_items_at_K)\n",
        "            a_r+=len(rel_rec_items_at_K) / tot_rel_items\n",
        "\n",
        "\n",
        "            tot_precision_causal = []\n",
        "            for k in range(1,K+1):\n",
        "                tot_precision_causal.append(len(set(causal[:k]) & set(rel_items)) / len(causal[:k]))\n",
        "\n",
        "            tot_precision_attrib = []\n",
        "            for k in range(1,K+1):\n",
        "                tot_precision_attrib.append(len(set(attrib[:k]) & set(rel_items)) / len(attrib[:k]))\n",
        "\n",
        "\n",
        "\n",
        "            average_precision_causal += np.mean(np.asarray(tot_precision_causal))\n",
        "            average_precision_attrib += np.mean(np.asarray(tot_precision_attrib))\n",
        "\n",
        "            counter+=1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    multimodal_repr = torch.stack(multimodal_repr).squeeze(1)\n",
        "\n",
        "    #causal\n",
        "    concept_repr = torch.stack(concept_repr).squeeze(1)\n",
        "\n",
        "\n",
        "    #attribution\n",
        "    concept_repr1 = torch.stack(concept_repr1).squeeze(1)\n",
        "\n",
        "    #HM\n",
        "    concept_repr2 = torch.stack(concept_repr2).squeeze(1)\n",
        "\n",
        "    print('mean precision causal@5',c_p/counter)\n",
        "    print('mean recall causal@5', c_r/counter)\n",
        "\n",
        "    print('mean precision attrb@5',a_p/counter)\n",
        "    print('mean recall attrb@5', a_r/counter)\n",
        "\n",
        "    print('MAP@5 Causal ', average_precision_causal/counter)\n",
        "    print('MAP@5 Attrib ', average_precision_attrib/counter)\n",
        "\n",
        "    #     print('kendall tau', np.mean(cr))\n",
        "\n",
        "    #     print('spearmans rho', np.mean(rr))\n",
        "\n",
        "\n",
        "    #     print('-----------CAUSAL----------')\n",
        "    #     get_sim(multimodal_repr, concept_repr)\n",
        "\n",
        "    #     print('-----------Attribution----------')\n",
        "    #     get_sim(multimodal_repr, concept_repr1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T20:32:37.392335Z",
          "iopub.execute_input": "2024-09-21T20:32:37.392633Z",
          "iopub.status.idle": "2024-09-21T20:32:37.464151Z",
          "shell.execute_reply.started": "2024-09-21T20:32:37.392610Z",
          "shell.execute_reply": "2024-09-21T20:32:37.463487Z"
        },
        "trusted": true,
        "id": "ZRqOgFe8ZeXz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "baire = ['ig', 'saliency', 'deeplift', 'deepliftshap', 'gradshap', 'ipxgrad']\n",
        "#R\n",
        "#baire = ['ig', 'saliency']\n",
        "import captum\n",
        "from scipy import stats\n",
        "for fu in range(len(baire)):\n",
        "\n",
        "\n",
        "    vb_wrapper = VB_wrapper(vb)\n",
        "    vb_wrapper.eval()\n",
        "    vb_wrapper.zero_grad()\n",
        "\n",
        "    if baire[fu]=='ig':\n",
        "        ig = IntegratedGradients(vb_wrapper)\n",
        "    elif baire[fu]=='saliency':\n",
        "        ig = Saliency(vb_wrapper)\n",
        "    elif baire[fu]=='deeplift':\n",
        "        ig = DeepLift(vb_wrapper)\n",
        "    elif baire[fu]=='deepliftshap':\n",
        "        ig = DeepLiftShap(vb_wrapper)\n",
        "    elif baire[fu]=='gradshap':\n",
        "        ig = GradientShap(vb_wrapper)\n",
        "    elif baire[fu]=='ipxgrad':\n",
        "        ig = InputXGradient(vb_wrapper)\n",
        "\n",
        "    cr, rr, multimodal_repr, concept_repr, concept_repr1, y_p = call_sim()\n",
        "    print('kendall tau', cr)\n",
        "\n",
        "    print('spearmans rho', rr)\n",
        "\n",
        "\n",
        "    print('-----------CAUSAL----------')\n",
        "    get_sim(multimodal_repr, concept_repr, y_p)\n",
        "\n",
        "    print('-----------Attribution----------')\n",
        "    get_sim(multimodal_repr, concept_repr1, y_p)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-09-21T16:32:42.816783Z",
          "iopub.execute_input": "2024-09-21T16:32:42.817478Z",
          "iopub.status.idle": "2024-09-21T19:33:03.037662Z",
          "shell.execute_reply.started": "2024-09-21T16:32:42.817449Z",
          "shell.execute_reply": "2024-09-21T19:33:03.036610Z"
        },
        "trusted": true,
        "id": "lSJ5HJ3GZeX0",
        "outputId": "8a177609-2adf-4797-e321-62d5e61ef004"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stderr",
          "text": "660it [31:01,  2.82s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau 0.017468805704099824\nspearmans rho 0.025549613784907905\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  0.008098233891712154 LAS std  0.020280097712266153\nLUS mean  0.010606060606060607 LUS std  0.014050937114387431\nComprehensiveness mean  0.030086562362112858 Comprehensiveness std  0.007783830092908213\nSufficiency mean  0.09202200748261212 Sufficiency std  0.007372510478802781\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.654955001545523\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.5608076764318705\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "660it [28:29,  2.59s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau 0.09001782531194297\nspearmans rho 0.12701003846514683\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  0.016926325706168366 LAS std  0.022812571090289217\nLUS mean  0.02727272727272727 LUS std  0.032354782581913065\nComprehensiveness mean  0.02261328329591747 Comprehensiveness std  0.004557108313404918\nSufficiency mean  0.1216594507720999 Sufficiency std  0.010984987868956452\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.6646014591818938\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.4794210207587984\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "660it [28:36,  2.60s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau 0.0006139829669241431\nspearmans rho -0.0005410138537073547\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.01631036074746959 LAS std  0.02999251312894323\nLUS mean  0.015151515151515152 LUS std  0.013551927136362362\nComprehensiveness mean  0.023832615545371583 Comprehensiveness std  0.01786771557996474\nSufficiency mean  0.03199714611875478 Sufficiency std  0.014257871961736978\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.6746766835003326\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.6510928809837339\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "660it [30:54,  2.81s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau -0.003188750247573776\nspearmans rho -0.004778434499796731\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.02150363254198749 LAS std  0.049714698131504934\nLUS mean  0.015151515151515152 LUS std  0.02953574043881504\nComprehensiveness mean  0.03665027568448015 Comprehensiveness std  0.02289451146956208\nSufficiency mean  0.02238656802755675 Sufficiency std  0.016016848358500334\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.6641544052776915\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.6651474255718599\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "660it [29:59,  2.73s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau 0.013250148544266193\nspearmans rho 0.01847577946649154\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  0.014917943790943553 LAS std  0.013153169678185282\nLUS mean  0.0015151515151515152 LUS std  0.019403406780099542\nComprehensiveness mean  0.008504464488489695 Comprehensiveness std  0.017475354686386377\nSufficiency mean  0.12935284659861357 Sufficiency std  0.021366246386833477\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.6507170402552058\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.44028560286700974\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "660it [29:24,  2.67s/it]\n",
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": "kendall tau 0.0002574767280649636\nspearmans rho 0.00015636238546455316\n-----------CAUSAL----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.008095216620637075 LAS std  0.035688532927307094\nLUS mean  -0.01666666666666667 LUS std  0.04872101572973796\nComprehensiveness mean  0.00811038536593361 Comprehensiveness std  0.03121915988703886\nSufficiency mean  0.12454541966743307 Sufficiency std  0.017887271340604773\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.627808260631571\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.48217012378817936\n-----------Attribution----------\n(660, 1536)\n(660, 768)\n(660, 768)\n[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1]\nLAS mean  -0.012777101357375576 LAS std  0.04279469907067488\nLUS mean  0.019696969696969695 LUS std  0.015599439607556059\nComprehensiveness mean  0.026786906871118767 Comprehensiveness std  0.022038640593994484\nSufficiency mean  0.04114234023514524 Sufficiency std  0.01627941740168946\nAvg. f1 between prediction of proposed model and SVM w/ both inp and exp 0.6804192767284819\nAvg. f1 between prediction of proposed model and SVM w/ only inp 0.6276673185098957\nAvg. f1 between prediction of proposed model and SVM w/ only exp 0.6787446970632948\n",
          "output_type": "stream"
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9PF6akRrZeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aYNEAQBhZeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "megK8e-yZeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0LQSuSSEZeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Z_wIoXyZeYR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dK1n0metZeYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xNuMrJYqZeYS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYTFMCJxZeYS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}